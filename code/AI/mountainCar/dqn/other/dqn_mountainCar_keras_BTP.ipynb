{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dqn_mountainCar_keras_BTP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFv4sst6GQ-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import gym\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.optimizers import Adam\n",
        "from collections import deque\n",
        "import random\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LKVMSk4GSzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MountainCarTrain:\n",
        "    def __init__(self,env):\n",
        "        self.env=env\n",
        "        self.gamma=0.99\n",
        "\n",
        "        self.epsilon = 1\n",
        "        self.epsilon_decay = 0.05\n",
        "\n",
        "        self.epsilon_min=0.01\n",
        "\n",
        "\n",
        "        self.learingRate=0.001\n",
        "\n",
        "        self.replayBuffer=deque(maxlen=20000)\n",
        "        self.trainNetwork=self.createNetwork()\n",
        "\n",
        "        self.episodeNum=400\n",
        "\n",
        "        self.iterationNum=201 #max is 200\n",
        "\n",
        "        self.numPickFromBuffer=32\n",
        "\n",
        "        self.targetNetwork=self.createNetwork()\n",
        "\n",
        "        self.targetNetwork.set_weights(self.trainNetwork.get_weights())\n",
        "\n",
        "    def createNetwork(self):\n",
        "        model = models.Sequential()\n",
        "        state_shape = self.env.observation_space.shape\n",
        "\n",
        "        model.add(layers.Dense(24, activation='relu', input_shape=state_shape))\n",
        "        model.add(layers.Dense(48, activation='relu'))\n",
        "        model.add(layers.Dense(self.env.action_space.n,activation='linear'))\n",
        "        # model.compile(optimizer=optimizers.RMSprop(lr=self.learingRate), loss=losses.mean_squared_error)\n",
        "        model.compile(loss='mse', optimizer=Adam(lr=self.learingRate))\n",
        "        return model\n",
        "\n",
        "    def getBestAction(self,state):\n",
        "\n",
        "        self.epsilon = max(self.epsilon_min, self.epsilon)\n",
        "\n",
        "        if np.random.rand(1) < self.epsilon:\n",
        "            action = np.random.randint(0, 3)\n",
        "        else:\n",
        "            action=np.argmax(self.trainNetwork.predict(state)[0])\n",
        "\n",
        "        return action\n",
        "\n",
        "    \n",
        "\n",
        "    def trainFromBuffer_Boost(self):\n",
        "        if len(self.replayBuffer) < self.numPickFromBuffer:\n",
        "            return\n",
        "        samples = random.sample(self.replayBuffer,self.numPickFromBuffer)\n",
        "        npsamples = np.array(samples)\n",
        "        states_temp, actions_temp, rewards_temp, newstates_temp, dones_temp = np.hsplit(npsamples, 5)\n",
        "        states = np.concatenate((np.squeeze(states_temp[:])), axis = 0)\n",
        "        rewards = rewards_temp.reshape(self.numPickFromBuffer,).astype(float)\n",
        "        targets = self.trainNetwork.predict(states)\n",
        "        newstates = np.concatenate(np.concatenate(newstates_temp))\n",
        "        dones = np.concatenate(dones_temp).astype(bool)\n",
        "        notdones = ~dones\n",
        "        notdones = notdones.astype(float)\n",
        "        dones = dones.astype(float)\n",
        "        Q_futures = self.targetNetwork.predict(newstates).max(axis = 1)\n",
        "        targets[(np.arange(self.numPickFromBuffer), actions_temp.reshape(self.numPickFromBuffer,).astype(int))] = rewards * dones + (rewards + Q_futures * self.gamma)*notdones\n",
        "        self.trainNetwork.fit(states, targets, epochs=1, verbose=0)\n",
        "\n",
        "\n",
        "\n",
        "    def trainFromBuffer(self):\n",
        "        if len(self.replayBuffer) < self.numPickFromBuffer:\n",
        "            return\n",
        "\n",
        "        samples = random.sample(self.replayBuffer,self.numPickFromBuffer)\n",
        "\n",
        "        states = []\n",
        "        newStates=[]\n",
        "        for sample in samples:\n",
        "            state, action, reward, new_state, done = sample\n",
        "            states.append(state)\n",
        "            newStates.append(new_state)\n",
        "\n",
        "        newArray = np.array(states)\n",
        "        states = newArray.reshape(self.numPickFromBuffer, 2)\n",
        "\n",
        "        newArray2 = np.array(newStates)\n",
        "        newStates = newArray2.reshape(self.numPickFromBuffer, 2)\n",
        "\n",
        "        targets = self.trainNetwork.predict(states)\n",
        "        new_state_targets=self.targetNetwork.predict(newStates)\n",
        "\n",
        "        i=0\n",
        "        for sample in samples:\n",
        "            state, action, reward, new_state, done = sample\n",
        "            target = targets[i]\n",
        "            if done:\n",
        "                target[action] = reward\n",
        "            else:\n",
        "                Q_future = max(new_state_targets[i])\n",
        "                target[action] = reward + Q_future * self.gamma\n",
        "            i+=1\n",
        "\n",
        "        return self.trainNetwork.fit(states, targets, epochs=1, verbose=0)\n",
        "\n",
        "\n",
        "    def orginalTry(self,currentState,eps):\n",
        "        rewardSum = 0\n",
        "        max_position=-99\n",
        "\n",
        "        for i in range(self.iterationNum):\n",
        "            bestAction = self.getBestAction(currentState)\n",
        "\n",
        "            #show the animation every 50 eps\n",
        "            # if eps%50==0:\n",
        "            #     env.render()\n",
        "\n",
        "            new_state, reward, done, _ = env.step(bestAction)\n",
        "\n",
        "            new_state = new_state.reshape(1, 2)\n",
        "\n",
        "            # # Keep track of max position\n",
        "            if new_state[0][0] > max_position:\n",
        "                max_position = new_state[0][0]\n",
        "\n",
        "\n",
        "            # # Adjust reward for task completion\n",
        "            if new_state[0][0] >= 0.5:\n",
        "                reward += 10\n",
        "\n",
        "            self.replayBuffer.append([currentState, bestAction, reward, new_state, done])\n",
        "\n",
        "        #Or you can use self.trainFromBuffer_Boost(), it is a matrix wise version for boosting \n",
        "            history = self.trainFromBuffer()\n",
        "\n",
        "            rewardSum += reward\n",
        "\n",
        "            currentState = new_state\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        if i >= 199:\n",
        "            print(\"Failed to finish task in epsoide {}\".format(eps))\n",
        "        else:\n",
        "            print(\"Success in epsoide {}, used {} iterations!\".format(eps, i))\n",
        "            self.trainNetwork.save('./trainNetworkInEPS{}.h5'.format(eps))\n",
        "\n",
        "        #Sync\n",
        "        self.targetNetwork.set_weights(self.trainNetwork.get_weights())\n",
        "\n",
        "        print(\"now epsilon is {}, the reward is {} maxPosition is {}\".format(max(self.epsilon_min, self.epsilon), rewardSum,max_position))\n",
        "        self.epsilon -= self.epsilon_decay\n",
        "        return history\n",
        "    def start(self):\n",
        "        for eps in range(self.episodeNum):\n",
        "            currentState=env.reset().reshape(1,2)\n",
        "            history = self.orginalTry(currentState, eps)\n",
        "        return history\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpWOgD15GonS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = gym.make('MountainCar-v0')\n",
        "dqn=MountainCarTrain(env=env)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRMPhCTKGrZ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e1b23b5a-d5f6-45f3-e6df-bec679090c78"
      },
      "source": [
        "history = dqn.start()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Failed to finish task in epsoide 0\n",
            "now epsilon is 1, the reward is -200.0 maxPosition is -0.40751411176267016\n",
            "Failed to finish task in epsoide 1\n",
            "now epsilon is 0.95, the reward is -200.0 maxPosition is -0.44865127429668056\n",
            "Failed to finish task in epsoide 2\n",
            "now epsilon is 0.8999999999999999, the reward is -200.0 maxPosition is -0.38286885569625695\n",
            "Failed to finish task in epsoide 3\n",
            "now epsilon is 0.8499999999999999, the reward is -200.0 maxPosition is -0.39874603327495\n",
            "Failed to finish task in epsoide 4\n",
            "now epsilon is 0.7999999999999998, the reward is -200.0 maxPosition is -0.3560192255141096\n",
            "Failed to finish task in epsoide 5\n",
            "now epsilon is 0.7499999999999998, the reward is -200.0 maxPosition is -0.3780991564963042\n",
            "Failed to finish task in epsoide 6\n",
            "now epsilon is 0.6999999999999997, the reward is -200.0 maxPosition is -0.3153063362626761\n",
            "Failed to finish task in epsoide 7\n",
            "now epsilon is 0.6499999999999997, the reward is -200.0 maxPosition is -0.2744966265604925\n",
            "Failed to finish task in epsoide 8\n",
            "now epsilon is 0.5999999999999996, the reward is -200.0 maxPosition is -0.4177310452387498\n",
            "Failed to finish task in epsoide 9\n",
            "now epsilon is 0.5499999999999996, the reward is -200.0 maxPosition is -0.3494918683924643\n",
            "Failed to finish task in epsoide 10\n",
            "now epsilon is 0.4999999999999996, the reward is -200.0 maxPosition is -0.39789816661457283\n",
            "Failed to finish task in epsoide 11\n",
            "now epsilon is 0.4499999999999996, the reward is -200.0 maxPosition is -0.15978260177474418\n",
            "Failed to finish task in epsoide 12\n",
            "now epsilon is 0.39999999999999963, the reward is -200.0 maxPosition is -0.2913684158227325\n",
            "Failed to finish task in epsoide 13\n",
            "now epsilon is 0.34999999999999964, the reward is -200.0 maxPosition is -0.3061486495488811\n",
            "Failed to finish task in epsoide 14\n",
            "now epsilon is 0.29999999999999966, the reward is -200.0 maxPosition is -0.29507594061376236\n",
            "Failed to finish task in epsoide 15\n",
            "now epsilon is 0.24999999999999967, the reward is -200.0 maxPosition is -0.2134363393630785\n",
            "Failed to finish task in epsoide 16\n",
            "now epsilon is 0.19999999999999968, the reward is -200.0 maxPosition is 0.022888094960223825\n",
            "Failed to finish task in epsoide 17\n",
            "now epsilon is 0.1499999999999997, the reward is -200.0 maxPosition is -0.3359736637356763\n",
            "Failed to finish task in epsoide 18\n",
            "now epsilon is 0.09999999999999969, the reward is -200.0 maxPosition is 0.045254577496017336\n",
            "Failed to finish task in epsoide 19\n",
            "now epsilon is 0.049999999999999684, the reward is -200.0 maxPosition is -0.07074290058695207\n",
            "Failed to finish task in epsoide 20\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.3277538229802648\n",
            "Failed to finish task in epsoide 21\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.005084187175261077\n",
            "Success in epsoide 22, used 142 iterations!\n",
            "now epsilon is 0.01, the reward is -133.0 maxPosition is 0.5193263539245806\n",
            "Failed to finish task in epsoide 23\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.00288739086995506\n",
            "Failed to finish task in epsoide 24\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.07759007938419717\n",
            "Failed to finish task in epsoide 25\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.04336503025644943\n",
            "Failed to finish task in epsoide 26\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.07589232466416468\n",
            "Failed to finish task in epsoide 27\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.236562210207037\n",
            "Failed to finish task in epsoide 28\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.13601232855853282\n",
            "Failed to finish task in epsoide 29\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.07782256407895084\n",
            "Failed to finish task in epsoide 30\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.1206735206419261\n",
            "Failed to finish task in epsoide 31\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.06768685219873485\n",
            "Failed to finish task in epsoide 32\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.13706764467983315\n",
            "Failed to finish task in epsoide 33\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.17696909435738237\n",
            "Failed to finish task in epsoide 34\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.1253823435187719\n",
            "Failed to finish task in epsoide 35\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.2366011688959382\n",
            "Failed to finish task in epsoide 36\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.3621571192235748\n",
            "Failed to finish task in epsoide 37\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.1392623702945575\n",
            "Failed to finish task in epsoide 38\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.47955301487407215\n",
            "Failed to finish task in epsoide 39\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.23946680615379912\n",
            "Failed to finish task in epsoide 40\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.19152093239706727\n",
            "Failed to finish task in epsoide 41\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.14533606278593267\n",
            "Failed to finish task in epsoide 42\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.10546089159652104\n",
            "Failed to finish task in epsoide 43\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.009884353362857153\n",
            "Failed to finish task in epsoide 44\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.09340219294792412\n",
            "Failed to finish task in epsoide 45\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.25795287132410183\n",
            "Failed to finish task in epsoide 46\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.2640078825654038\n",
            "Failed to finish task in epsoide 47\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.020418216459801387\n",
            "Failed to finish task in epsoide 48\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.2343773555444106\n",
            "Failed to finish task in epsoide 49\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.08019589177820018\n",
            "Failed to finish task in epsoide 50\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.0997599082576976\n",
            "Failed to finish task in epsoide 51\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.14471067181124533\n",
            "Success in epsoide 52, used 180 iterations!\n",
            "now epsilon is 0.01, the reward is -171.0 maxPosition is 0.5195683690642258\n",
            "Failed to finish task in epsoide 53\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.24057698704463334\n",
            "Failed to finish task in epsoide 54\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.14148282424167816\n",
            "Failed to finish task in epsoide 55\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.20204672684681585\n",
            "Failed to finish task in epsoide 56\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.3017778655696424\n",
            "Failed to finish task in epsoide 57\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.2277779859777975\n",
            "Failed to finish task in epsoide 58\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.029372145781678655\n",
            "Failed to finish task in epsoide 59\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.2000049967101482\n",
            "Failed to finish task in epsoide 60\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.01597535430086624\n",
            "Failed to finish task in epsoide 61\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.14450666940719087\n",
            "Success in epsoide 62, used 112 iterations!\n",
            "now epsilon is 0.01, the reward is -103.0 maxPosition is 0.5144787878012895\n",
            "Failed to finish task in epsoide 63\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.2927636683631945\n",
            "Failed to finish task in epsoide 64\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.18755150820798971\n",
            "Success in epsoide 65, used 115 iterations!\n",
            "now epsilon is 0.01, the reward is -106.0 maxPosition is 0.5187978134667636\n",
            "Failed to finish task in epsoide 66\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.004432855775150863\n",
            "Failed to finish task in epsoide 67\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.1700597320617083\n",
            "Failed to finish task in epsoide 68\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.09624231427335692\n",
            "Failed to finish task in epsoide 69\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.24987207771158879\n",
            "Failed to finish task in epsoide 70\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.19428224924433743\n",
            "Failed to finish task in epsoide 71\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.12870361886159806\n",
            "Failed to finish task in epsoide 72\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.33857620394455945\n",
            "Failed to finish task in epsoide 73\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.15799979023719565\n",
            "Failed to finish task in epsoide 74\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.1419792045192815\n",
            "Failed to finish task in epsoide 75\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.2202641845853418\n",
            "Failed to finish task in epsoide 76\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.28532304507201345\n",
            "Failed to finish task in epsoide 77\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.06719020374136625\n",
            "Success in epsoide 78, used 156 iterations!\n",
            "now epsilon is 0.01, the reward is -147.0 maxPosition is 0.5136191808056363\n",
            "Failed to finish task in epsoide 79\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.14504276100113087\n",
            "Failed to finish task in epsoide 80\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.036598506775332565\n",
            "Failed to finish task in epsoide 81\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.042810037060933455\n",
            "Failed to finish task in epsoide 82\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.22848628573514757\n",
            "Failed to finish task in epsoide 83\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.22998409707369408\n",
            "Failed to finish task in epsoide 84\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.3251404824819974\n",
            "Failed to finish task in epsoide 85\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.11116665790744722\n",
            "Failed to finish task in epsoide 86\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.11498880217476726\n",
            "Failed to finish task in epsoide 87\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.05840773562338305\n",
            "Failed to finish task in epsoide 88\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.035234610909304236\n",
            "Failed to finish task in epsoide 89\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.20387794445489035\n",
            "Failed to finish task in epsoide 90\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.32629601731341173\n",
            "Failed to finish task in epsoide 91\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.11493288625280895\n",
            "Failed to finish task in epsoide 92\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.06342454261835491\n",
            "Success in epsoide 93, used 155 iterations!\n",
            "now epsilon is 0.01, the reward is -146.0 maxPosition is 0.5115335036607225\n",
            "Success in epsoide 94, used 191 iterations!\n",
            "now epsilon is 0.01, the reward is -182.0 maxPosition is 0.5045036861320796\n",
            "Failed to finish task in epsoide 95\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.024259486857905948\n",
            "Failed to finish task in epsoide 96\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.05183159034629045\n",
            "Failed to finish task in epsoide 97\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.01101992550234986\n",
            "Success in epsoide 98, used 196 iterations!\n",
            "now epsilon is 0.01, the reward is -187.0 maxPosition is 0.5374420573501655\n",
            "Success in epsoide 99, used 156 iterations!\n",
            "now epsilon is 0.01, the reward is -147.0 maxPosition is 0.5187271987443646\n",
            "Failed to finish task in epsoide 100\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.0754410647343109\n",
            "Failed to finish task in epsoide 101\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.10172938950619848\n",
            "Success in epsoide 102, used 176 iterations!\n",
            "now epsilon is 0.01, the reward is -167.0 maxPosition is 0.5383467735956502\n",
            "Failed to finish task in epsoide 103\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.12289461041653088\n",
            "Failed to finish task in epsoide 104\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.2176557086590515\n",
            "Failed to finish task in epsoide 105\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.002075267638797361\n",
            "Success in epsoide 106, used 161 iterations!\n",
            "now epsilon is 0.01, the reward is -152.0 maxPosition is 0.5170354677639887\n",
            "Failed to finish task in epsoide 107\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.20840515198021958\n",
            "Success in epsoide 108, used 153 iterations!\n",
            "now epsilon is 0.01, the reward is -144.0 maxPosition is 0.5144653780843348\n",
            "Failed to finish task in epsoide 109\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.23383940656626717\n",
            "Failed to finish task in epsoide 110\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.02966881581970847\n",
            "Failed to finish task in epsoide 111\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.2321156414256277\n",
            "Success in epsoide 112, used 163 iterations!\n",
            "now epsilon is 0.01, the reward is -154.0 maxPosition is 0.5202228903747497\n",
            "Failed to finish task in epsoide 113\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.06899019140921746\n",
            "Failed to finish task in epsoide 114\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.023006417651851973\n",
            "Success in epsoide 115, used 163 iterations!\n",
            "now epsilon is 0.01, the reward is -154.0 maxPosition is 0.5124510627801858\n",
            "Success in epsoide 116, used 198 iterations!\n",
            "now epsilon is 0.01, the reward is -189.0 maxPosition is 0.5306301170282547\n",
            "Failed to finish task in epsoide 117\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.2180394521619595\n",
            "Failed to finish task in epsoide 118\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.0025689306859144403\n",
            "Failed to finish task in epsoide 119\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.02284668470423405\n",
            "Success in epsoide 120, used 125 iterations!\n",
            "now epsilon is 0.01, the reward is -116.0 maxPosition is 0.5015417406301297\n",
            "Failed to finish task in epsoide 121\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.11160847008266335\n",
            "Success in epsoide 122, used 119 iterations!\n",
            "now epsilon is 0.01, the reward is -110.0 maxPosition is 0.5047248798000095\n",
            "Success in epsoide 123, used 124 iterations!\n",
            "now epsilon is 0.01, the reward is -115.0 maxPosition is 0.5072157416549486\n",
            "Failed to finish task in epsoide 124\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.1404396849109053\n",
            "Failed to finish task in epsoide 125\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.04078994032819707\n",
            "Failed to finish task in epsoide 126\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.03888829665165947\n",
            "Failed to finish task in epsoide 127\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.2514426017138547\n",
            "Failed to finish task in epsoide 128\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.027451363457567667\n",
            "Failed to finish task in epsoide 129\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.05849693879633456\n",
            "Success in epsoide 130, used 171 iterations!\n",
            "now epsilon is 0.01, the reward is -162.0 maxPosition is 0.5421276164246832\n",
            "Success in epsoide 131, used 167 iterations!\n",
            "now epsilon is 0.01, the reward is -158.0 maxPosition is 0.5247661498856577\n",
            "Failed to finish task in epsoide 132\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.15028251047167482\n",
            "Success in epsoide 133, used 198 iterations!\n",
            "now epsilon is 0.01, the reward is -189.0 maxPosition is 0.5127649004335787\n",
            "Failed to finish task in epsoide 134\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.27388860606856513\n",
            "Success in epsoide 135, used 169 iterations!\n",
            "now epsilon is 0.01, the reward is -160.0 maxPosition is 0.5109732300225849\n",
            "Success in epsoide 136, used 115 iterations!\n",
            "now epsilon is 0.01, the reward is -106.0 maxPosition is 0.5165140888271963\n",
            "Failed to finish task in epsoide 137\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.1751514557387022\n",
            "Failed to finish task in epsoide 138\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.2574070974636509\n",
            "Success in epsoide 139, used 122 iterations!\n",
            "now epsilon is 0.01, the reward is -113.0 maxPosition is 0.5040589028002261\n",
            "Success in epsoide 140, used 144 iterations!\n",
            "now epsilon is 0.01, the reward is -135.0 maxPosition is 0.5055302687291656\n",
            "Success in epsoide 141, used 179 iterations!\n",
            "now epsilon is 0.01, the reward is -170.0 maxPosition is 0.5071175868517345\n",
            "Success in epsoide 142, used 176 iterations!\n",
            "now epsilon is 0.01, the reward is -167.0 maxPosition is 0.5115061902583601\n",
            "Success in epsoide 143, used 162 iterations!\n",
            "now epsilon is 0.01, the reward is -153.0 maxPosition is 0.5028818925455839\n",
            "Failed to finish task in epsoide 144\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.22817310086404016\n",
            "Success in epsoide 145, used 160 iterations!\n",
            "now epsilon is 0.01, the reward is -151.0 maxPosition is 0.5069114770830047\n",
            "Failed to finish task in epsoide 146\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.12978799265353588\n",
            "Failed to finish task in epsoide 147\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.11785588786278621\n",
            "Failed to finish task in epsoide 148\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.17045207765957915\n",
            "Success in epsoide 149, used 196 iterations!\n",
            "now epsilon is 0.01, the reward is -187.0 maxPosition is 0.5215723838392536\n",
            "Success in epsoide 150, used 118 iterations!\n",
            "now epsilon is 0.01, the reward is -109.0 maxPosition is 0.5099672627004376\n",
            "Failed to finish task in epsoide 151\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.2830387418287199\n",
            "Failed to finish task in epsoide 152\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.16913576051849796\n",
            "Failed to finish task in epsoide 153\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.10600597158101575\n",
            "Failed to finish task in epsoide 154\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.17231131548425088\n",
            "Success in epsoide 155, used 146 iterations!\n",
            "now epsilon is 0.01, the reward is -137.0 maxPosition is 0.5368577983788596\n",
            "Failed to finish task in epsoide 156\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.4146803476472864\n",
            "Success in epsoide 157, used 196 iterations!\n",
            "now epsilon is 0.01, the reward is -187.0 maxPosition is 0.5451681240948013\n",
            "Failed to finish task in epsoide 158\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.14316803369276143\n",
            "Failed to finish task in epsoide 159\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.07238527132642207\n",
            "Success in epsoide 160, used 155 iterations!\n",
            "now epsilon is 0.01, the reward is -146.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 161, used 148 iterations!\n",
            "now epsilon is 0.01, the reward is -139.0 maxPosition is 0.5231112925492792\n",
            "Success in epsoide 162, used 182 iterations!\n",
            "now epsilon is 0.01, the reward is -173.0 maxPosition is 0.5034137532733868\n",
            "Success in epsoide 163, used 125 iterations!\n",
            "now epsilon is 0.01, the reward is -116.0 maxPosition is 0.5138446104963432\n",
            "Success in epsoide 164, used 187 iterations!\n",
            "now epsilon is 0.01, the reward is -178.0 maxPosition is 0.512283444180206\n",
            "Success in epsoide 165, used 143 iterations!\n",
            "now epsilon is 0.01, the reward is -134.0 maxPosition is 0.5147667433232092\n",
            "Success in epsoide 166, used 178 iterations!\n",
            "now epsilon is 0.01, the reward is -169.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 167, used 149 iterations!\n",
            "now epsilon is 0.01, the reward is -140.0 maxPosition is 0.5122791811083387\n",
            "Success in epsoide 168, used 150 iterations!\n",
            "now epsilon is 0.01, the reward is -141.0 maxPosition is 0.5368577983788596\n",
            "Failed to finish task in epsoide 169\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.1459038459110961\n",
            "Success in epsoide 170, used 132 iterations!\n",
            "now epsilon is 0.01, the reward is -123.0 maxPosition is 0.5202919778881189\n",
            "Failed to finish task in epsoide 171\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.053673996807359556\n",
            "Success in epsoide 172, used 180 iterations!\n",
            "now epsilon is 0.01, the reward is -171.0 maxPosition is 0.5368577983788596\n",
            "Failed to finish task in epsoide 173\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.10268872445374698\n",
            "Success in epsoide 174, used 163 iterations!\n",
            "now epsilon is 0.01, the reward is -154.0 maxPosition is 0.5218140709970847\n",
            "Success in epsoide 175, used 183 iterations!\n",
            "now epsilon is 0.01, the reward is -174.0 maxPosition is 0.5370889101206813\n",
            "Success in epsoide 176, used 172 iterations!\n",
            "now epsilon is 0.01, the reward is -163.0 maxPosition is 0.5421547578844275\n",
            "Success in epsoide 177, used 134 iterations!\n",
            "now epsilon is 0.01, the reward is -125.0 maxPosition is 0.5359060417936004\n",
            "Success in epsoide 178, used 169 iterations!\n",
            "now epsilon is 0.01, the reward is -160.0 maxPosition is 0.5226835059907717\n",
            "Success in epsoide 179, used 184 iterations!\n",
            "now epsilon is 0.01, the reward is -175.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 180, used 108 iterations!\n",
            "now epsilon is 0.01, the reward is -99.0 maxPosition is 0.5111892437371532\n",
            "Success in epsoide 181, used 127 iterations!\n",
            "now epsilon is 0.01, the reward is -118.0 maxPosition is 0.5310760310813293\n",
            "Success in epsoide 182, used 154 iterations!\n",
            "now epsilon is 0.01, the reward is -145.0 maxPosition is 0.5076662399300618\n",
            "Failed to finish task in epsoide 183\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.17517737602079114\n",
            "Success in epsoide 184, used 98 iterations!\n",
            "now epsilon is 0.01, the reward is -89.0 maxPosition is 0.5138181801836856\n",
            "Success in epsoide 185, used 163 iterations!\n",
            "now epsilon is 0.01, the reward is -154.0 maxPosition is 0.5368577983788596\n",
            "Failed to finish task in epsoide 186\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5042410815542449\n",
            "Success in epsoide 187, used 83 iterations!\n",
            "now epsilon is 0.01, the reward is -74.0 maxPosition is 0.5183675132820726\n",
            "Failed to finish task in epsoide 188\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.4376689695757199\n",
            "Success in epsoide 189, used 154 iterations!\n",
            "now epsilon is 0.01, the reward is -145.0 maxPosition is 0.5036689234281658\n",
            "Failed to finish task in epsoide 190\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5767116840051119\n",
            "Success in epsoide 191, used 166 iterations!\n",
            "now epsilon is 0.01, the reward is -157.0 maxPosition is 0.504364897255146\n",
            "Success in epsoide 192, used 171 iterations!\n",
            "now epsilon is 0.01, the reward is -162.0 maxPosition is 0.5368577983788596\n",
            "Failed to finish task in epsoide 193\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5034914419159303\n",
            "Success in epsoide 194, used 153 iterations!\n",
            "now epsilon is 0.01, the reward is -144.0 maxPosition is 0.5139991877366241\n",
            "Success in epsoide 195, used 88 iterations!\n",
            "now epsilon is 0.01, the reward is -79.0 maxPosition is 0.5255651464588568\n",
            "Failed to finish task in epsoide 196\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.34373274413156724\n",
            "Failed to finish task in epsoide 197\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.345946479652496\n",
            "Failed to finish task in epsoide 198\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.03562076609375478\n",
            "Success in epsoide 199, used 191 iterations!\n",
            "now epsilon is 0.01, the reward is -182.0 maxPosition is 0.5064931527294974\n",
            "Success in epsoide 200, used 188 iterations!\n",
            "now epsilon is 0.01, the reward is -179.0 maxPosition is 0.5103727298238879\n",
            "Failed to finish task in epsoide 201\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5782544055870323\n",
            "Failed to finish task in epsoide 202\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.4557313094543227\n",
            "Failed to finish task in epsoide 203\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5045638439513618\n",
            "Failed to finish task in epsoide 204\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.4001268285431625\n",
            "Failed to finish task in epsoide 205\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5782032150622332\n",
            "Failed to finish task in epsoide 206\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.4837743654070119\n",
            "Failed to finish task in epsoide 207\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.47054187696527483\n",
            "Failed to finish task in epsoide 208\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.4921130012949297\n",
            "Success in epsoide 209, used 154 iterations!\n",
            "now epsilon is 0.01, the reward is -145.0 maxPosition is 0.5041030268499412\n",
            "Success in epsoide 210, used 165 iterations!\n",
            "now epsilon is 0.01, the reward is -156.0 maxPosition is 0.5243050453197777\n",
            "Failed to finish task in epsoide 211\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.45032605335937775\n",
            "Failed to finish task in epsoide 212\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5842410641954128\n",
            "Failed to finish task in epsoide 213\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5263107952690502\n",
            "Failed to finish task in epsoide 214\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.41702833954055357\n",
            "Failed to finish task in epsoide 215\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5210816832270817\n",
            "Failed to finish task in epsoide 216\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.4797158612183525\n",
            "Failed to finish task in epsoide 217\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.561863053784444\n",
            "Failed to finish task in epsoide 218\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5779001342617529\n",
            "Failed to finish task in epsoide 219\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.46092770601801725\n",
            "Failed to finish task in epsoide 220\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.47693009919108764\n",
            "Success in epsoide 221, used 175 iterations!\n",
            "now epsilon is 0.01, the reward is -166.0 maxPosition is 0.5011174123338616\n",
            "Success in epsoide 222, used 89 iterations!\n",
            "now epsilon is 0.01, the reward is -80.0 maxPosition is 0.5141062087307207\n",
            "Success in epsoide 223, used 166 iterations!\n",
            "now epsilon is 0.01, the reward is -157.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 224, used 95 iterations!\n",
            "now epsilon is 0.01, the reward is -86.0 maxPosition is 0.5191068708519756\n",
            "Failed to finish task in epsoide 225\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.1699194207606273\n",
            "Success in epsoide 226, used 141 iterations!\n",
            "now epsilon is 0.01, the reward is -132.0 maxPosition is 0.5056511228370583\n",
            "Success in epsoide 227, used 179 iterations!\n",
            "now epsilon is 0.01, the reward is -170.0 maxPosition is 0.5368577983788596\n",
            "Failed to finish task in epsoide 228\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5495439315889876\n",
            "Success in epsoide 229, used 89 iterations!\n",
            "now epsilon is 0.01, the reward is -80.0 maxPosition is 0.5214264141505163\n",
            "Failed to finish task in epsoide 230\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.026660126439644424\n",
            "Success in epsoide 231, used 157 iterations!\n",
            "now epsilon is 0.01, the reward is -148.0 maxPosition is 0.5368577983788596\n",
            "Failed to finish task in epsoide 232\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.17620011077667425\n",
            "Success in epsoide 233, used 98 iterations!\n",
            "now epsilon is 0.01, the reward is -89.0 maxPosition is 0.5013222146351873\n",
            "Success in epsoide 234, used 160 iterations!\n",
            "now epsilon is 0.01, the reward is -151.0 maxPosition is 0.5437543007344479\n",
            "Failed to finish task in epsoide 235\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5303838251276173\n",
            "Failed to finish task in epsoide 236\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.16254018843300647\n",
            "Failed to finish task in epsoide 237\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.06893212441421194\n",
            "Failed to finish task in epsoide 238\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.38031774436860083\n",
            "Success in epsoide 239, used 164 iterations!\n",
            "now epsilon is 0.01, the reward is -155.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 240, used 86 iterations!\n",
            "now epsilon is 0.01, the reward is -77.0 maxPosition is 0.5126918289788606\n",
            "Success in epsoide 241, used 161 iterations!\n",
            "now epsilon is 0.01, the reward is -152.0 maxPosition is 0.5165977389186027\n",
            "Failed to finish task in epsoide 242\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5395621652990836\n",
            "Failed to finish task in epsoide 243\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.42271897796002933\n",
            "Success in epsoide 244, used 84 iterations!\n",
            "now epsilon is 0.01, the reward is -75.0 maxPosition is 0.5205681119937724\n",
            "Success in epsoide 245, used 91 iterations!\n",
            "now epsilon is 0.01, the reward is -82.0 maxPosition is 0.5051075866453025\n",
            "Success in epsoide 246, used 164 iterations!\n",
            "now epsilon is 0.01, the reward is -155.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 247, used 159 iterations!\n",
            "now epsilon is 0.01, the reward is -150.0 maxPosition is 0.5174427638514221\n",
            "Success in epsoide 248, used 103 iterations!\n",
            "now epsilon is 0.01, the reward is -94.0 maxPosition is 0.5070829958143488\n",
            "Success in epsoide 249, used 156 iterations!\n",
            "now epsilon is 0.01, the reward is -147.0 maxPosition is 0.5368577983788596\n",
            "Failed to finish task in epsoide 250\n",
            "now epsilon is 0.01, the reward is -190.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 251, used 144 iterations!\n",
            "now epsilon is 0.01, the reward is -135.0 maxPosition is 0.5368577983788596\n",
            "Failed to finish task in epsoide 252\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.4148244474989906\n",
            "Success in epsoide 253, used 149 iterations!\n",
            "now epsilon is 0.01, the reward is -140.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 254, used 84 iterations!\n",
            "now epsilon is 0.01, the reward is -75.0 maxPosition is 0.5055961902517335\n",
            "Success in epsoide 255, used 160 iterations!\n",
            "now epsilon is 0.01, the reward is -151.0 maxPosition is 0.5165178169891165\n",
            "Success in epsoide 256, used 142 iterations!\n",
            "now epsilon is 0.01, the reward is -133.0 maxPosition is 0.5265758293781637\n",
            "Success in epsoide 257, used 148 iterations!\n",
            "now epsilon is 0.01, the reward is -139.0 maxPosition is 0.5368577983788596\n",
            "Failed to finish task in epsoide 258\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.24101646944167865\n",
            "Success in epsoide 259, used 84 iterations!\n",
            "now epsilon is 0.01, the reward is -75.0 maxPosition is 0.5030651676853544\n",
            "Success in epsoide 260, used 96 iterations!\n",
            "now epsilon is 0.01, the reward is -87.0 maxPosition is 0.5043077873215682\n",
            "Success in epsoide 261, used 140 iterations!\n",
            "now epsilon is 0.01, the reward is -131.0 maxPosition is 0.5189678707257186\n",
            "Success in epsoide 262, used 92 iterations!\n",
            "now epsilon is 0.01, the reward is -83.0 maxPosition is 0.5090680450121932\n",
            "Success in epsoide 263, used 85 iterations!\n",
            "now epsilon is 0.01, the reward is -76.0 maxPosition is 0.5109119924372441\n",
            "Success in epsoide 264, used 141 iterations!\n",
            "now epsilon is 0.01, the reward is -132.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 265, used 95 iterations!\n",
            "now epsilon is 0.01, the reward is -86.0 maxPosition is 0.5116276349749725\n",
            "Success in epsoide 266, used 162 iterations!\n",
            "now epsilon is 0.01, the reward is -153.0 maxPosition is 0.5348577983788596\n",
            "Success in epsoide 267, used 148 iterations!\n",
            "now epsilon is 0.01, the reward is -139.0 maxPosition is 0.5348577983788596\n",
            "Success in epsoide 268, used 148 iterations!\n",
            "now epsilon is 0.01, the reward is -139.0 maxPosition is 0.5348577983788596\n",
            "Success in epsoide 269, used 180 iterations!\n",
            "now epsilon is 0.01, the reward is -171.0 maxPosition is 0.5348577983788596\n",
            "Success in epsoide 270, used 144 iterations!\n",
            "now epsilon is 0.01, the reward is -135.0 maxPosition is 0.5348577983788596\n",
            "Success in epsoide 271, used 142 iterations!\n",
            "now epsilon is 0.01, the reward is -133.0 maxPosition is 0.5011424634690417\n",
            "Success in epsoide 272, used 146 iterations!\n",
            "now epsilon is 0.01, the reward is -137.0 maxPosition is 0.5239456369029324\n",
            "Success in epsoide 273, used 89 iterations!\n",
            "now epsilon is 0.01, the reward is -80.0 maxPosition is 0.5057399786417699\n",
            "Success in epsoide 274, used 149 iterations!\n",
            "now epsilon is 0.01, the reward is -140.0 maxPosition is 0.5308428942261745\n",
            "Success in epsoide 275, used 178 iterations!\n",
            "now epsilon is 0.01, the reward is -169.0 maxPosition is 0.5348577983788596\n",
            "Success in epsoide 276, used 141 iterations!\n",
            "now epsilon is 0.01, the reward is -132.0 maxPosition is 0.505662886654018\n",
            "Success in epsoide 277, used 140 iterations!\n",
            "now epsilon is 0.01, the reward is -131.0 maxPosition is 0.5348577983788596\n",
            "Success in epsoide 278, used 145 iterations!\n",
            "now epsilon is 0.01, the reward is -136.0 maxPosition is 0.5251472057736833\n",
            "Success in epsoide 279, used 91 iterations!\n",
            "now epsilon is 0.01, the reward is -82.0 maxPosition is 0.5078660721714321\n",
            "Failed to finish task in epsoide 280\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.3768635409354654\n",
            "Success in epsoide 281, used 152 iterations!\n",
            "now epsilon is 0.01, the reward is -143.0 maxPosition is 0.5348577983788596\n",
            "Success in epsoide 282, used 143 iterations!\n",
            "now epsilon is 0.01, the reward is -134.0 maxPosition is 0.5091091422656672\n",
            "Success in epsoide 283, used 145 iterations!\n",
            "now epsilon is 0.01, the reward is -136.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 284, used 114 iterations!\n",
            "now epsilon is 0.01, the reward is -105.0 maxPosition is 0.5016564916574552\n",
            "Success in epsoide 285, used 143 iterations!\n",
            "now epsilon is 0.01, the reward is -134.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 286, used 149 iterations!\n",
            "now epsilon is 0.01, the reward is -140.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 287, used 119 iterations!\n",
            "now epsilon is 0.01, the reward is -110.0 maxPosition is 0.5088371444976703\n",
            "Success in epsoide 288, used 90 iterations!\n",
            "now epsilon is 0.01, the reward is -81.0 maxPosition is 0.5148911200491719\n",
            "Success in epsoide 289, used 84 iterations!\n",
            "now epsilon is 0.01, the reward is -75.0 maxPosition is 0.5006979291011624\n",
            "Success in epsoide 290, used 169 iterations!\n",
            "now epsilon is 0.01, the reward is -160.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 291, used 159 iterations!\n",
            "now epsilon is 0.01, the reward is -150.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 292, used 91 iterations!\n",
            "now epsilon is 0.01, the reward is -82.0 maxPosition is 0.5036598143943264\n",
            "Failed to finish task in epsoide 293\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.40859489161586166\n",
            "Failed to finish task in epsoide 294\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.00036232946302964045\n",
            "Success in epsoide 295, used 142 iterations!\n",
            "now epsilon is 0.01, the reward is -133.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 296, used 147 iterations!\n",
            "now epsilon is 0.01, the reward is -138.0 maxPosition is 0.53382834164182\n",
            "Success in epsoide 297, used 171 iterations!\n",
            "now epsilon is 0.01, the reward is -162.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 298, used 150 iterations!\n",
            "now epsilon is 0.01, the reward is -141.0 maxPosition is 0.5012943268629708\n",
            "Success in epsoide 299, used 152 iterations!\n",
            "now epsilon is 0.01, the reward is -143.0 maxPosition is 0.5368577983788596\n",
            "Failed to finish task in epsoide 300\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.4629624446218262\n",
            "Success in epsoide 301, used 89 iterations!\n",
            "now epsilon is 0.01, the reward is -80.0 maxPosition is 0.5012737069634434\n",
            "Success in epsoide 302, used 183 iterations!\n",
            "now epsilon is 0.01, the reward is -174.0 maxPosition is 0.5070147457034374\n",
            "Success in epsoide 303, used 112 iterations!\n",
            "now epsilon is 0.01, the reward is -103.0 maxPosition is 0.5008475151585567\n",
            "Success in epsoide 304, used 159 iterations!\n",
            "now epsilon is 0.01, the reward is -150.0 maxPosition is 0.502343098735524\n",
            "Success in epsoide 305, used 147 iterations!\n",
            "now epsilon is 0.01, the reward is -138.0 maxPosition is 0.5062183508022278\n",
            "Failed to finish task in epsoide 306\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.4838386863585567\n",
            "Failed to finish task in epsoide 307\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5803230715228316\n",
            "Failed to finish task in epsoide 308\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.07595942495383158\n",
            "Success in epsoide 309, used 89 iterations!\n",
            "now epsilon is 0.01, the reward is -80.0 maxPosition is 0.5174109565864231\n",
            "Success in epsoide 310, used 150 iterations!\n",
            "now epsilon is 0.01, the reward is -141.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 311, used 147 iterations!\n",
            "now epsilon is 0.01, the reward is -138.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 312, used 180 iterations!\n",
            "now epsilon is 0.01, the reward is -171.0 maxPosition is 0.5005863486265466\n",
            "Success in epsoide 313, used 88 iterations!\n",
            "now epsilon is 0.01, the reward is -79.0 maxPosition is 0.5035456819166717\n",
            "Success in epsoide 314, used 139 iterations!\n",
            "now epsilon is 0.01, the reward is -130.0 maxPosition is 0.5368577983788596\n",
            "Failed to finish task in epsoide 315\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5655070427944536\n",
            "Success in epsoide 316, used 145 iterations!\n",
            "now epsilon is 0.01, the reward is -136.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 317, used 140 iterations!\n",
            "now epsilon is 0.01, the reward is -131.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 318, used 146 iterations!\n",
            "now epsilon is 0.01, the reward is -137.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 319, used 157 iterations!\n",
            "now epsilon is 0.01, the reward is -148.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 320, used 92 iterations!\n",
            "now epsilon is 0.01, the reward is -83.0 maxPosition is 0.5014370660121202\n",
            "Success in epsoide 321, used 161 iterations!\n",
            "now epsilon is 0.01, the reward is -152.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 322, used 138 iterations!\n",
            "now epsilon is 0.01, the reward is -129.0 maxPosition is 0.5202134132457957\n",
            "Success in epsoide 323, used 178 iterations!\n",
            "now epsilon is 0.01, the reward is -169.0 maxPosition is 0.5368577983788596\n",
            "Failed to finish task in epsoide 324\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.42041532858798275\n",
            "Success in epsoide 325, used 141 iterations!\n",
            "now epsilon is 0.01, the reward is -132.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 326, used 87 iterations!\n",
            "now epsilon is 0.01, the reward is -78.0 maxPosition is 0.5072914696607097\n",
            "Failed to finish task in epsoide 327\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.2166384906085706\n",
            "Success in epsoide 328, used 171 iterations!\n",
            "now epsilon is 0.01, the reward is -162.0 maxPosition is 0.5213185364635474\n",
            "Failed to finish task in epsoide 329\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.30956045447371716\n",
            "Success in epsoide 330, used 83 iterations!\n",
            "now epsilon is 0.01, the reward is -74.0 maxPosition is 0.5217786396656956\n",
            "Success in epsoide 331, used 101 iterations!\n",
            "now epsilon is 0.01, the reward is -92.0 maxPosition is 0.5016448969182595\n",
            "Success in epsoide 332, used 165 iterations!\n",
            "now epsilon is 0.01, the reward is -156.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 333, used 172 iterations!\n",
            "now epsilon is 0.01, the reward is -163.0 maxPosition is 0.5368577983788596\n",
            "Failed to finish task in epsoide 334\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.4869140825698949\n",
            "Success in epsoide 335, used 164 iterations!\n",
            "now epsilon is 0.01, the reward is -155.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 336, used 182 iterations!\n",
            "now epsilon is 0.01, the reward is -173.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 337, used 102 iterations!\n",
            "now epsilon is 0.01, the reward is -93.0 maxPosition is 0.5021662274569199\n",
            "Failed to finish task in epsoide 338\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5468271680295216\n",
            "Success in epsoide 339, used 174 iterations!\n",
            "now epsilon is 0.01, the reward is -165.0 maxPosition is 0.5273048368055935\n",
            "Success in epsoide 340, used 172 iterations!\n",
            "now epsilon is 0.01, the reward is -163.0 maxPosition is 0.5310168666150362\n",
            "Success in epsoide 341, used 165 iterations!\n",
            "now epsilon is 0.01, the reward is -156.0 maxPosition is 0.5388765510413682\n",
            "Success in epsoide 342, used 160 iterations!\n",
            "now epsilon is 0.01, the reward is -151.0 maxPosition is 0.5383901631291432\n",
            "Success in epsoide 343, used 154 iterations!\n",
            "now epsilon is 0.01, the reward is -145.0 maxPosition is 0.5038491073612663\n",
            "Failed to finish task in epsoide 344\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5950308611463141\n",
            "Success in epsoide 345, used 155 iterations!\n",
            "now epsilon is 0.01, the reward is -146.0 maxPosition is 0.5015244245515416\n",
            "Failed to finish task in epsoide 346\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5555316231255897\n",
            "Success in epsoide 347, used 160 iterations!\n",
            "now epsilon is 0.01, the reward is -151.0 maxPosition is 0.5025883158998355\n",
            "Success in epsoide 348, used 159 iterations!\n",
            "now epsilon is 0.01, the reward is -150.0 maxPosition is 0.5368577983788596\n",
            "Failed to finish task in epsoide 349\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is 0.20830308572515305\n",
            "Success in epsoide 350, used 157 iterations!\n",
            "now epsilon is 0.01, the reward is -148.0 maxPosition is 0.5077784473099222\n",
            "Success in epsoide 351, used 110 iterations!\n",
            "now epsilon is 0.01, the reward is -101.0 maxPosition is 0.5066256237581198\n",
            "Success in epsoide 352, used 153 iterations!\n",
            "now epsilon is 0.01, the reward is -144.0 maxPosition is 0.5368577983788596\n",
            "Failed to finish task in epsoide 353\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5669245979543602\n",
            "Success in epsoide 354, used 156 iterations!\n",
            "now epsilon is 0.01, the reward is -147.0 maxPosition is 0.5431527094326726\n",
            "Failed to finish task in epsoide 355\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5951133668360251\n",
            "Success in epsoide 356, used 168 iterations!\n",
            "now epsilon is 0.01, the reward is -159.0 maxPosition is 0.5219892743967612\n",
            "Success in epsoide 357, used 168 iterations!\n",
            "now epsilon is 0.01, the reward is -159.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 358, used 153 iterations!\n",
            "now epsilon is 0.01, the reward is -144.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 359, used 160 iterations!\n",
            "now epsilon is 0.01, the reward is -151.0 maxPosition is 0.5007436183353673\n",
            "Success in epsoide 360, used 154 iterations!\n",
            "now epsilon is 0.01, the reward is -145.0 maxPosition is 0.5368577983788596\n",
            "Failed to finish task in epsoide 361\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5902144900062894\n",
            "Failed to finish task in epsoide 362\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5723727427839365\n",
            "Success in epsoide 363, used 147 iterations!\n",
            "now epsilon is 0.01, the reward is -138.0 maxPosition is 0.5368577983788596\n",
            "Failed to finish task in epsoide 364\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5586680782795549\n",
            "Success in epsoide 365, used 154 iterations!\n",
            "now epsilon is 0.01, the reward is -145.0 maxPosition is 0.5368577983788596\n",
            "Failed to finish task in epsoide 366\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.584848379376283\n",
            "Success in epsoide 367, used 146 iterations!\n",
            "now epsilon is 0.01, the reward is -137.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 368, used 150 iterations!\n",
            "now epsilon is 0.01, the reward is -141.0 maxPosition is 0.5399306677780037\n",
            "Failed to finish task in epsoide 369\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.595942488544381\n",
            "Success in epsoide 370, used 152 iterations!\n",
            "now epsilon is 0.01, the reward is -143.0 maxPosition is 0.5213185364635474\n",
            "Success in epsoide 371, used 150 iterations!\n",
            "now epsilon is 0.01, the reward is -141.0 maxPosition is 0.5189186679456416\n",
            "Success in epsoide 372, used 147 iterations!\n",
            "now epsilon is 0.01, the reward is -138.0 maxPosition is 0.5168578023258621\n",
            "Success in epsoide 373, used 150 iterations!\n",
            "now epsilon is 0.01, the reward is -141.0 maxPosition is 0.5354355020115188\n",
            "Success in epsoide 374, used 146 iterations!\n",
            "now epsilon is 0.01, the reward is -137.0 maxPosition is 0.5031926186841096\n",
            "Failed to finish task in epsoide 375\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5856034764976646\n",
            "Success in epsoide 376, used 147 iterations!\n",
            "now epsilon is 0.01, the reward is -138.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 377, used 145 iterations!\n",
            "now epsilon is 0.01, the reward is -136.0 maxPosition is 0.5341359494843021\n",
            "Success in epsoide 378, used 144 iterations!\n",
            "now epsilon is 0.01, the reward is -135.0 maxPosition is 0.5176197902668407\n",
            "Failed to finish task in epsoide 379\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.57523205122563\n",
            "Failed to finish task in epsoide 380\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5823947133590538\n",
            "Success in epsoide 381, used 159 iterations!\n",
            "now epsilon is 0.01, the reward is -150.0 maxPosition is 0.519401930782063\n",
            "Success in epsoide 382, used 93 iterations!\n",
            "now epsilon is 0.01, the reward is -84.0 maxPosition is 0.5075562408707155\n",
            "Failed to finish task in epsoide 383\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5951286748376392\n",
            "Success in epsoide 384, used 149 iterations!\n",
            "now epsilon is 0.01, the reward is -140.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 385, used 151 iterations!\n",
            "now epsilon is 0.01, the reward is -142.0 maxPosition is 0.5205105023286288\n",
            "Failed to finish task in epsoide 386\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5793124435207505\n",
            "Success in epsoide 387, used 155 iterations!\n",
            "now epsilon is 0.01, the reward is -146.0 maxPosition is 0.5368577983788596\n",
            "Failed to finish task in epsoide 388\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5482856323206032\n",
            "Success in epsoide 389, used 150 iterations!\n",
            "now epsilon is 0.01, the reward is -141.0 maxPosition is 0.5306184377787105\n",
            "Success in epsoide 390, used 145 iterations!\n",
            "now epsilon is 0.01, the reward is -136.0 maxPosition is 0.502744603656821\n",
            "Failed to finish task in epsoide 391\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.594955917701635\n",
            "Failed to finish task in epsoide 392\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5926736397320641\n",
            "Success in epsoide 393, used 148 iterations!\n",
            "now epsilon is 0.01, the reward is -139.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 394, used 148 iterations!\n",
            "now epsilon is 0.01, the reward is -139.0 maxPosition is 0.502744603656821\n",
            "Failed to finish task in epsoide 395\n",
            "now epsilon is 0.01, the reward is -200.0 maxPosition is -0.5692122427926399\n",
            "Success in epsoide 396, used 146 iterations!\n",
            "now epsilon is 0.01, the reward is -137.0 maxPosition is 0.5295673648285222\n",
            "Success in epsoide 397, used 155 iterations!\n",
            "now epsilon is 0.01, the reward is -146.0 maxPosition is 0.531718286514371\n",
            "Success in epsoide 398, used 149 iterations!\n",
            "now epsilon is 0.01, the reward is -140.0 maxPosition is 0.5368577983788596\n",
            "Success in epsoide 399, used 144 iterations!\n",
            "now epsilon is 0.01, the reward is -135.0 maxPosition is 0.5368577983788596\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9OAejywPZ6J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8578ad7-9c72-4b17-bab7-d163b6a0d465"
      },
      "source": [
        "history.history.get('loss')[0]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.05781087279319763"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pquW-QsMjIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Plot training & validation accuracy values\n",
        "# plt.plot(history.history['episode_reward'])\n",
        "# # plt.plot(history.history['val_acc'])\n",
        "# plt.title('Model accuracy')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.legend(['Train', 'Test'], loc='upper left')\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj_zzpIfM5LT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "371e2830-415d-4632-c055-6b5da6ed197d"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model.png\t\t trainNetworkInEPS421.h5  trainNetworkInEPS705.h5\n",
            "sample_data\t\t trainNetworkInEPS422.h5  trainNetworkInEPS706.h5\n",
            "trainNetworkInEPS102.h5  trainNetworkInEPS423.h5  trainNetworkInEPS707.h5\n",
            "trainNetworkInEPS106.h5  trainNetworkInEPS424.h5  trainNetworkInEPS708.h5\n",
            "trainNetworkInEPS108.h5  trainNetworkInEPS425.h5  trainNetworkInEPS709.h5\n",
            "trainNetworkInEPS112.h5  trainNetworkInEPS426.h5  trainNetworkInEPS710.h5\n",
            "trainNetworkInEPS115.h5  trainNetworkInEPS427.h5  trainNetworkInEPS711.h5\n",
            "trainNetworkInEPS116.h5  trainNetworkInEPS428.h5  trainNetworkInEPS712.h5\n",
            "trainNetworkInEPS120.h5  trainNetworkInEPS429.h5  trainNetworkInEPS713.h5\n",
            "trainNetworkInEPS122.h5  trainNetworkInEPS430.h5  trainNetworkInEPS714.h5\n",
            "trainNetworkInEPS123.h5  trainNetworkInEPS431.h5  trainNetworkInEPS715.h5\n",
            "trainNetworkInEPS130.h5  trainNetworkInEPS432.h5  trainNetworkInEPS716.h5\n",
            "trainNetworkInEPS131.h5  trainNetworkInEPS433.h5  trainNetworkInEPS717.h5\n",
            "trainNetworkInEPS133.h5  trainNetworkInEPS434.h5  trainNetworkInEPS718.h5\n",
            "trainNetworkInEPS135.h5  trainNetworkInEPS435.h5  trainNetworkInEPS719.h5\n",
            "trainNetworkInEPS136.h5  trainNetworkInEPS436.h5  trainNetworkInEPS720.h5\n",
            "trainNetworkInEPS137.h5  trainNetworkInEPS437.h5  trainNetworkInEPS721.h5\n",
            "trainNetworkInEPS139.h5  trainNetworkInEPS438.h5  trainNetworkInEPS722.h5\n",
            "trainNetworkInEPS140.h5  trainNetworkInEPS439.h5  trainNetworkInEPS723.h5\n",
            "trainNetworkInEPS141.h5  trainNetworkInEPS440.h5  trainNetworkInEPS724.h5\n",
            "trainNetworkInEPS142.h5  trainNetworkInEPS441.h5  trainNetworkInEPS725.h5\n",
            "trainNetworkInEPS143.h5  trainNetworkInEPS442.h5  trainNetworkInEPS726.h5\n",
            "trainNetworkInEPS145.h5  trainNetworkInEPS443.h5  trainNetworkInEPS727.h5\n",
            "trainNetworkInEPS149.h5  trainNetworkInEPS444.h5  trainNetworkInEPS728.h5\n",
            "trainNetworkInEPS150.h5  trainNetworkInEPS445.h5  trainNetworkInEPS729.h5\n",
            "trainNetworkInEPS151.h5  trainNetworkInEPS446.h5  trainNetworkInEPS730.h5\n",
            "trainNetworkInEPS155.h5  trainNetworkInEPS447.h5  trainNetworkInEPS732.h5\n",
            "trainNetworkInEPS156.h5  trainNetworkInEPS448.h5  trainNetworkInEPS734.h5\n",
            "trainNetworkInEPS157.h5  trainNetworkInEPS449.h5  trainNetworkInEPS735.h5\n",
            "trainNetworkInEPS159.h5  trainNetworkInEPS450.h5  trainNetworkInEPS736.h5\n",
            "trainNetworkInEPS160.h5  trainNetworkInEPS451.h5  trainNetworkInEPS737.h5\n",
            "trainNetworkInEPS161.h5  trainNetworkInEPS452.h5  trainNetworkInEPS738.h5\n",
            "trainNetworkInEPS162.h5  trainNetworkInEPS453.h5  trainNetworkInEPS739.h5\n",
            "trainNetworkInEPS163.h5  trainNetworkInEPS454.h5  trainNetworkInEPS740.h5\n",
            "trainNetworkInEPS164.h5  trainNetworkInEPS455.h5  trainNetworkInEPS741.h5\n",
            "trainNetworkInEPS165.h5  trainNetworkInEPS456.h5  trainNetworkInEPS742.h5\n",
            "trainNetworkInEPS166.h5  trainNetworkInEPS457.h5  trainNetworkInEPS743.h5\n",
            "trainNetworkInEPS167.h5  trainNetworkInEPS458.h5  trainNetworkInEPS744.h5\n",
            "trainNetworkInEPS168.h5  trainNetworkInEPS459.h5  trainNetworkInEPS745.h5\n",
            "trainNetworkInEPS169.h5  trainNetworkInEPS460.h5  trainNetworkInEPS747.h5\n",
            "trainNetworkInEPS170.h5  trainNetworkInEPS461.h5  trainNetworkInEPS748.h5\n",
            "trainNetworkInEPS171.h5  trainNetworkInEPS462.h5  trainNetworkInEPS749.h5\n",
            "trainNetworkInEPS172.h5  trainNetworkInEPS463.h5  trainNetworkInEPS750.h5\n",
            "trainNetworkInEPS174.h5  trainNetworkInEPS464.h5  trainNetworkInEPS751.h5\n",
            "trainNetworkInEPS175.h5  trainNetworkInEPS465.h5  trainNetworkInEPS752.h5\n",
            "trainNetworkInEPS176.h5  trainNetworkInEPS466.h5  trainNetworkInEPS753.h5\n",
            "trainNetworkInEPS177.h5  trainNetworkInEPS467.h5  trainNetworkInEPS754.h5\n",
            "trainNetworkInEPS178.h5  trainNetworkInEPS468.h5  trainNetworkInEPS755.h5\n",
            "trainNetworkInEPS179.h5  trainNetworkInEPS469.h5  trainNetworkInEPS756.h5\n",
            "trainNetworkInEPS180.h5  trainNetworkInEPS470.h5  trainNetworkInEPS757.h5\n",
            "trainNetworkInEPS181.h5  trainNetworkInEPS471.h5  trainNetworkInEPS760.h5\n",
            "trainNetworkInEPS182.h5  trainNetworkInEPS472.h5  trainNetworkInEPS761.h5\n",
            "trainNetworkInEPS183.h5  trainNetworkInEPS473.h5  trainNetworkInEPS762.h5\n",
            "trainNetworkInEPS184.h5  trainNetworkInEPS474.h5  trainNetworkInEPS763.h5\n",
            "trainNetworkInEPS185.h5  trainNetworkInEPS475.h5  trainNetworkInEPS765.h5\n",
            "trainNetworkInEPS186.h5  trainNetworkInEPS476.h5  trainNetworkInEPS767.h5\n",
            "trainNetworkInEPS187.h5  trainNetworkInEPS477.h5  trainNetworkInEPS768.h5\n",
            "trainNetworkInEPS189.h5  trainNetworkInEPS478.h5  trainNetworkInEPS769.h5\n",
            "trainNetworkInEPS190.h5  trainNetworkInEPS479.h5  trainNetworkInEPS770.h5\n",
            "trainNetworkInEPS191.h5  trainNetworkInEPS480.h5  trainNetworkInEPS771.h5\n",
            "trainNetworkInEPS192.h5  trainNetworkInEPS481.h5  trainNetworkInEPS772.h5\n",
            "trainNetworkInEPS194.h5  trainNetworkInEPS482.h5  trainNetworkInEPS773.h5\n",
            "trainNetworkInEPS195.h5  trainNetworkInEPS483.h5  trainNetworkInEPS774.h5\n",
            "trainNetworkInEPS197.h5  trainNetworkInEPS484.h5  trainNetworkInEPS775.h5\n",
            "trainNetworkInEPS199.h5  trainNetworkInEPS485.h5  trainNetworkInEPS776.h5\n",
            "trainNetworkInEPS19.h5\t trainNetworkInEPS486.h5  trainNetworkInEPS777.h5\n",
            "trainNetworkInEPS200.h5  trainNetworkInEPS487.h5  trainNetworkInEPS778.h5\n",
            "trainNetworkInEPS201.h5  trainNetworkInEPS488.h5  trainNetworkInEPS779.h5\n",
            "trainNetworkInEPS202.h5  trainNetworkInEPS489.h5  trainNetworkInEPS780.h5\n",
            "trainNetworkInEPS203.h5  trainNetworkInEPS490.h5  trainNetworkInEPS782.h5\n",
            "trainNetworkInEPS205.h5  trainNetworkInEPS491.h5  trainNetworkInEPS783.h5\n",
            "trainNetworkInEPS206.h5  trainNetworkInEPS492.h5  trainNetworkInEPS785.h5\n",
            "trainNetworkInEPS209.h5  trainNetworkInEPS493.h5  trainNetworkInEPS78.h5\n",
            "trainNetworkInEPS210.h5  trainNetworkInEPS494.h5  trainNetworkInEPS792.h5\n",
            "trainNetworkInEPS211.h5  trainNetworkInEPS495.h5  trainNetworkInEPS793.h5\n",
            "trainNetworkInEPS213.h5  trainNetworkInEPS496.h5  trainNetworkInEPS794.h5\n",
            "trainNetworkInEPS214.h5  trainNetworkInEPS497.h5  trainNetworkInEPS797.h5\n",
            "trainNetworkInEPS215.h5  trainNetworkInEPS498.h5  trainNetworkInEPS798.h5\n",
            "trainNetworkInEPS216.h5  trainNetworkInEPS499.h5  trainNetworkInEPS799.h5\n",
            "trainNetworkInEPS217.h5  trainNetworkInEPS500.h5  trainNetworkInEPS800.h5\n",
            "trainNetworkInEPS218.h5  trainNetworkInEPS501.h5  trainNetworkInEPS801.h5\n",
            "trainNetworkInEPS219.h5  trainNetworkInEPS502.h5  trainNetworkInEPS802.h5\n",
            "trainNetworkInEPS21.h5\t trainNetworkInEPS503.h5  trainNetworkInEPS804.h5\n",
            "trainNetworkInEPS220.h5  trainNetworkInEPS504.h5  trainNetworkInEPS805.h5\n",
            "trainNetworkInEPS221.h5  trainNetworkInEPS505.h5  trainNetworkInEPS806.h5\n",
            "trainNetworkInEPS222.h5  trainNetworkInEPS506.h5  trainNetworkInEPS807.h5\n",
            "trainNetworkInEPS223.h5  trainNetworkInEPS507.h5  trainNetworkInEPS808.h5\n",
            "trainNetworkInEPS224.h5  trainNetworkInEPS508.h5  trainNetworkInEPS809.h5\n",
            "trainNetworkInEPS225.h5  trainNetworkInEPS509.h5  trainNetworkInEPS810.h5\n",
            "trainNetworkInEPS226.h5  trainNetworkInEPS510.h5  trainNetworkInEPS812.h5\n",
            "trainNetworkInEPS227.h5  trainNetworkInEPS511.h5  trainNetworkInEPS813.h5\n",
            "trainNetworkInEPS228.h5  trainNetworkInEPS512.h5  trainNetworkInEPS814.h5\n",
            "trainNetworkInEPS229.h5  trainNetworkInEPS513.h5  trainNetworkInEPS815.h5\n",
            "trainNetworkInEPS22.h5\t trainNetworkInEPS514.h5  trainNetworkInEPS816.h5\n",
            "trainNetworkInEPS230.h5  trainNetworkInEPS515.h5  trainNetworkInEPS817.h5\n",
            "trainNetworkInEPS231.h5  trainNetworkInEPS516.h5  trainNetworkInEPS818.h5\n",
            "trainNetworkInEPS232.h5  trainNetworkInEPS517.h5  trainNetworkInEPS819.h5\n",
            "trainNetworkInEPS233.h5  trainNetworkInEPS518.h5  trainNetworkInEPS820.h5\n",
            "trainNetworkInEPS234.h5  trainNetworkInEPS519.h5  trainNetworkInEPS821.h5\n",
            "trainNetworkInEPS235.h5  trainNetworkInEPS520.h5  trainNetworkInEPS822.h5\n",
            "trainNetworkInEPS236.h5  trainNetworkInEPS521.h5  trainNetworkInEPS823.h5\n",
            "trainNetworkInEPS237.h5  trainNetworkInEPS522.h5  trainNetworkInEPS824.h5\n",
            "trainNetworkInEPS238.h5  trainNetworkInEPS523.h5  trainNetworkInEPS825.h5\n",
            "trainNetworkInEPS239.h5  trainNetworkInEPS525.h5  trainNetworkInEPS826.h5\n",
            "trainNetworkInEPS240.h5  trainNetworkInEPS526.h5  trainNetworkInEPS827.h5\n",
            "trainNetworkInEPS241.h5  trainNetworkInEPS527.h5  trainNetworkInEPS828.h5\n",
            "trainNetworkInEPS243.h5  trainNetworkInEPS528.h5  trainNetworkInEPS829.h5\n",
            "trainNetworkInEPS244.h5  trainNetworkInEPS529.h5  trainNetworkInEPS831.h5\n",
            "trainNetworkInEPS245.h5  trainNetworkInEPS52.h5   trainNetworkInEPS832.h5\n",
            "trainNetworkInEPS246.h5  trainNetworkInEPS530.h5  trainNetworkInEPS833.h5\n",
            "trainNetworkInEPS247.h5  trainNetworkInEPS531.h5  trainNetworkInEPS834.h5\n",
            "trainNetworkInEPS248.h5  trainNetworkInEPS532.h5  trainNetworkInEPS835.h5\n",
            "trainNetworkInEPS249.h5  trainNetworkInEPS533.h5  trainNetworkInEPS836.h5\n",
            "trainNetworkInEPS250.h5  trainNetworkInEPS534.h5  trainNetworkInEPS837.h5\n",
            "trainNetworkInEPS251.h5  trainNetworkInEPS535.h5  trainNetworkInEPS838.h5\n",
            "trainNetworkInEPS253.h5  trainNetworkInEPS537.h5  trainNetworkInEPS839.h5\n",
            "trainNetworkInEPS254.h5  trainNetworkInEPS538.h5  trainNetworkInEPS840.h5\n",
            "trainNetworkInEPS255.h5  trainNetworkInEPS539.h5  trainNetworkInEPS841.h5\n",
            "trainNetworkInEPS256.h5  trainNetworkInEPS540.h5  trainNetworkInEPS842.h5\n",
            "trainNetworkInEPS257.h5  trainNetworkInEPS543.h5  trainNetworkInEPS843.h5\n",
            "trainNetworkInEPS258.h5  trainNetworkInEPS544.h5  trainNetworkInEPS844.h5\n",
            "trainNetworkInEPS259.h5  trainNetworkInEPS545.h5  trainNetworkInEPS845.h5\n",
            "trainNetworkInEPS260.h5  trainNetworkInEPS546.h5  trainNetworkInEPS846.h5\n",
            "trainNetworkInEPS261.h5  trainNetworkInEPS547.h5  trainNetworkInEPS847.h5\n",
            "trainNetworkInEPS262.h5  trainNetworkInEPS548.h5  trainNetworkInEPS848.h5\n",
            "trainNetworkInEPS263.h5  trainNetworkInEPS549.h5  trainNetworkInEPS849.h5\n",
            "trainNetworkInEPS264.h5  trainNetworkInEPS550.h5  trainNetworkInEPS850.h5\n",
            "trainNetworkInEPS265.h5  trainNetworkInEPS551.h5  trainNetworkInEPS851.h5\n",
            "trainNetworkInEPS266.h5  trainNetworkInEPS552.h5  trainNetworkInEPS852.h5\n",
            "trainNetworkInEPS267.h5  trainNetworkInEPS553.h5  trainNetworkInEPS853.h5\n",
            "trainNetworkInEPS268.h5  trainNetworkInEPS554.h5  trainNetworkInEPS854.h5\n",
            "trainNetworkInEPS269.h5  trainNetworkInEPS555.h5  trainNetworkInEPS855.h5\n",
            "trainNetworkInEPS270.h5  trainNetworkInEPS556.h5  trainNetworkInEPS856.h5\n",
            "trainNetworkInEPS271.h5  trainNetworkInEPS557.h5  trainNetworkInEPS857.h5\n",
            "trainNetworkInEPS272.h5  trainNetworkInEPS558.h5  trainNetworkInEPS858.h5\n",
            "trainNetworkInEPS273.h5  trainNetworkInEPS559.h5  trainNetworkInEPS859.h5\n",
            "trainNetworkInEPS274.h5  trainNetworkInEPS560.h5  trainNetworkInEPS85.h5\n",
            "trainNetworkInEPS275.h5  trainNetworkInEPS562.h5  trainNetworkInEPS860.h5\n",
            "trainNetworkInEPS276.h5  trainNetworkInEPS563.h5  trainNetworkInEPS861.h5\n",
            "trainNetworkInEPS277.h5  trainNetworkInEPS564.h5  trainNetworkInEPS862.h5\n",
            "trainNetworkInEPS278.h5  trainNetworkInEPS565.h5  trainNetworkInEPS863.h5\n",
            "trainNetworkInEPS279.h5  trainNetworkInEPS566.h5  trainNetworkInEPS864.h5\n",
            "trainNetworkInEPS281.h5  trainNetworkInEPS567.h5  trainNetworkInEPS865.h5\n",
            "trainNetworkInEPS282.h5  trainNetworkInEPS568.h5  trainNetworkInEPS866.h5\n",
            "trainNetworkInEPS283.h5  trainNetworkInEPS569.h5  trainNetworkInEPS868.h5\n",
            "trainNetworkInEPS284.h5  trainNetworkInEPS570.h5  trainNetworkInEPS869.h5\n",
            "trainNetworkInEPS285.h5  trainNetworkInEPS571.h5  trainNetworkInEPS870.h5\n",
            "trainNetworkInEPS286.h5  trainNetworkInEPS572.h5  trainNetworkInEPS871.h5\n",
            "trainNetworkInEPS287.h5  trainNetworkInEPS573.h5  trainNetworkInEPS872.h5\n",
            "trainNetworkInEPS288.h5  trainNetworkInEPS574.h5  trainNetworkInEPS873.h5\n",
            "trainNetworkInEPS289.h5  trainNetworkInEPS575.h5  trainNetworkInEPS874.h5\n",
            "trainNetworkInEPS290.h5  trainNetworkInEPS576.h5  trainNetworkInEPS875.h5\n",
            "trainNetworkInEPS291.h5  trainNetworkInEPS577.h5  trainNetworkInEPS876.h5\n",
            "trainNetworkInEPS292.h5  trainNetworkInEPS578.h5  trainNetworkInEPS877.h5\n",
            "trainNetworkInEPS293.h5  trainNetworkInEPS579.h5  trainNetworkInEPS878.h5\n",
            "trainNetworkInEPS294.h5  trainNetworkInEPS580.h5  trainNetworkInEPS879.h5\n",
            "trainNetworkInEPS295.h5  trainNetworkInEPS581.h5  trainNetworkInEPS880.h5\n",
            "trainNetworkInEPS296.h5  trainNetworkInEPS582.h5  trainNetworkInEPS881.h5\n",
            "trainNetworkInEPS297.h5  trainNetworkInEPS583.h5  trainNetworkInEPS882.h5\n",
            "trainNetworkInEPS298.h5  trainNetworkInEPS584.h5  trainNetworkInEPS883.h5\n",
            "trainNetworkInEPS299.h5  trainNetworkInEPS585.h5  trainNetworkInEPS884.h5\n",
            "trainNetworkInEPS300.h5  trainNetworkInEPS586.h5  trainNetworkInEPS885.h5\n",
            "trainNetworkInEPS301.h5  trainNetworkInEPS587.h5  trainNetworkInEPS886.h5\n",
            "trainNetworkInEPS302.h5  trainNetworkInEPS588.h5  trainNetworkInEPS887.h5\n",
            "trainNetworkInEPS303.h5  trainNetworkInEPS589.h5  trainNetworkInEPS888.h5\n",
            "trainNetworkInEPS304.h5  trainNetworkInEPS590.h5  trainNetworkInEPS889.h5\n",
            "trainNetworkInEPS305.h5  trainNetworkInEPS591.h5  trainNetworkInEPS890.h5\n",
            "trainNetworkInEPS306.h5  trainNetworkInEPS592.h5  trainNetworkInEPS891.h5\n",
            "trainNetworkInEPS307.h5  trainNetworkInEPS593.h5  trainNetworkInEPS892.h5\n",
            "trainNetworkInEPS308.h5  trainNetworkInEPS594.h5  trainNetworkInEPS893.h5\n",
            "trainNetworkInEPS309.h5  trainNetworkInEPS595.h5  trainNetworkInEPS894.h5\n",
            "trainNetworkInEPS310.h5  trainNetworkInEPS596.h5  trainNetworkInEPS895.h5\n",
            "trainNetworkInEPS311.h5  trainNetworkInEPS597.h5  trainNetworkInEPS896.h5\n",
            "trainNetworkInEPS312.h5  trainNetworkInEPS598.h5  trainNetworkInEPS897.h5\n",
            "trainNetworkInEPS313.h5  trainNetworkInEPS599.h5  trainNetworkInEPS898.h5\n",
            "trainNetworkInEPS314.h5  trainNetworkInEPS600.h5  trainNetworkInEPS899.h5\n",
            "trainNetworkInEPS315.h5  trainNetworkInEPS601.h5  trainNetworkInEPS900.h5\n",
            "trainNetworkInEPS316.h5  trainNetworkInEPS602.h5  trainNetworkInEPS901.h5\n",
            "trainNetworkInEPS317.h5  trainNetworkInEPS603.h5  trainNetworkInEPS902.h5\n",
            "trainNetworkInEPS318.h5  trainNetworkInEPS604.h5  trainNetworkInEPS903.h5\n",
            "trainNetworkInEPS319.h5  trainNetworkInEPS605.h5  trainNetworkInEPS904.h5\n",
            "trainNetworkInEPS320.h5  trainNetworkInEPS606.h5  trainNetworkInEPS905.h5\n",
            "trainNetworkInEPS321.h5  trainNetworkInEPS607.h5  trainNetworkInEPS906.h5\n",
            "trainNetworkInEPS322.h5  trainNetworkInEPS608.h5  trainNetworkInEPS907.h5\n",
            "trainNetworkInEPS323.h5  trainNetworkInEPS609.h5  trainNetworkInEPS908.h5\n",
            "trainNetworkInEPS324.h5  trainNetworkInEPS610.h5  trainNetworkInEPS909.h5\n",
            "trainNetworkInEPS325.h5  trainNetworkInEPS611.h5  trainNetworkInEPS910.h5\n",
            "trainNetworkInEPS326.h5  trainNetworkInEPS612.h5  trainNetworkInEPS911.h5\n",
            "trainNetworkInEPS327.h5  trainNetworkInEPS614.h5  trainNetworkInEPS912.h5\n",
            "trainNetworkInEPS328.h5  trainNetworkInEPS615.h5  trainNetworkInEPS913.h5\n",
            "trainNetworkInEPS329.h5  trainNetworkInEPS616.h5  trainNetworkInEPS914.h5\n",
            "trainNetworkInEPS330.h5  trainNetworkInEPS617.h5  trainNetworkInEPS915.h5\n",
            "trainNetworkInEPS331.h5  trainNetworkInEPS618.h5  trainNetworkInEPS916.h5\n",
            "trainNetworkInEPS332.h5  trainNetworkInEPS619.h5  trainNetworkInEPS917.h5\n",
            "trainNetworkInEPS333.h5  trainNetworkInEPS620.h5  trainNetworkInEPS918.h5\n",
            "trainNetworkInEPS334.h5  trainNetworkInEPS621.h5  trainNetworkInEPS919.h5\n",
            "trainNetworkInEPS335.h5  trainNetworkInEPS622.h5  trainNetworkInEPS920.h5\n",
            "trainNetworkInEPS336.h5  trainNetworkInEPS623.h5  trainNetworkInEPS921.h5\n",
            "trainNetworkInEPS337.h5  trainNetworkInEPS624.h5  trainNetworkInEPS922.h5\n",
            "trainNetworkInEPS338.h5  trainNetworkInEPS625.h5  trainNetworkInEPS923.h5\n",
            "trainNetworkInEPS339.h5  trainNetworkInEPS626.h5  trainNetworkInEPS924.h5\n",
            "trainNetworkInEPS340.h5  trainNetworkInEPS627.h5  trainNetworkInEPS925.h5\n",
            "trainNetworkInEPS341.h5  trainNetworkInEPS628.h5  trainNetworkInEPS926.h5\n",
            "trainNetworkInEPS342.h5  trainNetworkInEPS629.h5  trainNetworkInEPS927.h5\n",
            "trainNetworkInEPS343.h5  trainNetworkInEPS62.h5   trainNetworkInEPS928.h5\n",
            "trainNetworkInEPS344.h5  trainNetworkInEPS630.h5  trainNetworkInEPS929.h5\n",
            "trainNetworkInEPS345.h5  trainNetworkInEPS631.h5  trainNetworkInEPS930.h5\n",
            "trainNetworkInEPS346.h5  trainNetworkInEPS632.h5  trainNetworkInEPS931.h5\n",
            "trainNetworkInEPS347.h5  trainNetworkInEPS633.h5  trainNetworkInEPS932.h5\n",
            "trainNetworkInEPS348.h5  trainNetworkInEPS634.h5  trainNetworkInEPS933.h5\n",
            "trainNetworkInEPS349.h5  trainNetworkInEPS635.h5  trainNetworkInEPS934.h5\n",
            "trainNetworkInEPS350.h5  trainNetworkInEPS636.h5  trainNetworkInEPS935.h5\n",
            "trainNetworkInEPS351.h5  trainNetworkInEPS637.h5  trainNetworkInEPS936.h5\n",
            "trainNetworkInEPS352.h5  trainNetworkInEPS638.h5  trainNetworkInEPS937.h5\n",
            "trainNetworkInEPS353.h5  trainNetworkInEPS639.h5  trainNetworkInEPS938.h5\n",
            "trainNetworkInEPS354.h5  trainNetworkInEPS640.h5  trainNetworkInEPS939.h5\n",
            "trainNetworkInEPS356.h5  trainNetworkInEPS641.h5  trainNetworkInEPS93.h5\n",
            "trainNetworkInEPS357.h5  trainNetworkInEPS642.h5  trainNetworkInEPS940.h5\n",
            "trainNetworkInEPS358.h5  trainNetworkInEPS643.h5  trainNetworkInEPS941.h5\n",
            "trainNetworkInEPS359.h5  trainNetworkInEPS644.h5  trainNetworkInEPS942.h5\n",
            "trainNetworkInEPS360.h5  trainNetworkInEPS645.h5  trainNetworkInEPS943.h5\n",
            "trainNetworkInEPS361.h5  trainNetworkInEPS646.h5  trainNetworkInEPS944.h5\n",
            "trainNetworkInEPS363.h5  trainNetworkInEPS647.h5  trainNetworkInEPS945.h5\n",
            "trainNetworkInEPS364.h5  trainNetworkInEPS648.h5  trainNetworkInEPS946.h5\n",
            "trainNetworkInEPS365.h5  trainNetworkInEPS649.h5  trainNetworkInEPS947.h5\n",
            "trainNetworkInEPS366.h5  trainNetworkInEPS650.h5  trainNetworkInEPS948.h5\n",
            "trainNetworkInEPS367.h5  trainNetworkInEPS651.h5  trainNetworkInEPS949.h5\n",
            "trainNetworkInEPS368.h5  trainNetworkInEPS652.h5  trainNetworkInEPS94.h5\n",
            "trainNetworkInEPS369.h5  trainNetworkInEPS653.h5  trainNetworkInEPS950.h5\n",
            "trainNetworkInEPS370.h5  trainNetworkInEPS654.h5  trainNetworkInEPS951.h5\n",
            "trainNetworkInEPS371.h5  trainNetworkInEPS655.h5  trainNetworkInEPS952.h5\n",
            "trainNetworkInEPS372.h5  trainNetworkInEPS656.h5  trainNetworkInEPS953.h5\n",
            "trainNetworkInEPS373.h5  trainNetworkInEPS657.h5  trainNetworkInEPS954.h5\n",
            "trainNetworkInEPS374.h5  trainNetworkInEPS658.h5  trainNetworkInEPS955.h5\n",
            "trainNetworkInEPS376.h5  trainNetworkInEPS659.h5  trainNetworkInEPS956.h5\n",
            "trainNetworkInEPS377.h5  trainNetworkInEPS65.h5   trainNetworkInEPS957.h5\n",
            "trainNetworkInEPS378.h5  trainNetworkInEPS660.h5  trainNetworkInEPS958.h5\n",
            "trainNetworkInEPS379.h5  trainNetworkInEPS661.h5  trainNetworkInEPS959.h5\n",
            "trainNetworkInEPS380.h5  trainNetworkInEPS662.h5  trainNetworkInEPS960.h5\n",
            "trainNetworkInEPS381.h5  trainNetworkInEPS663.h5  trainNetworkInEPS961.h5\n",
            "trainNetworkInEPS382.h5  trainNetworkInEPS664.h5  trainNetworkInEPS962.h5\n",
            "trainNetworkInEPS383.h5  trainNetworkInEPS665.h5  trainNetworkInEPS963.h5\n",
            "trainNetworkInEPS384.h5  trainNetworkInEPS666.h5  trainNetworkInEPS964.h5\n",
            "trainNetworkInEPS385.h5  trainNetworkInEPS667.h5  trainNetworkInEPS965.h5\n",
            "trainNetworkInEPS386.h5  trainNetworkInEPS669.h5  trainNetworkInEPS966.h5\n",
            "trainNetworkInEPS387.h5  trainNetworkInEPS670.h5  trainNetworkInEPS967.h5\n",
            "trainNetworkInEPS388.h5  trainNetworkInEPS671.h5  trainNetworkInEPS968.h5\n",
            "trainNetworkInEPS389.h5  trainNetworkInEPS672.h5  trainNetworkInEPS969.h5\n",
            "trainNetworkInEPS390.h5  trainNetworkInEPS674.h5  trainNetworkInEPS970.h5\n",
            "trainNetworkInEPS391.h5  trainNetworkInEPS675.h5  trainNetworkInEPS972.h5\n",
            "trainNetworkInEPS392.h5  trainNetworkInEPS676.h5  trainNetworkInEPS973.h5\n",
            "trainNetworkInEPS393.h5  trainNetworkInEPS677.h5  trainNetworkInEPS974.h5\n",
            "trainNetworkInEPS394.h5  trainNetworkInEPS678.h5  trainNetworkInEPS975.h5\n",
            "trainNetworkInEPS395.h5  trainNetworkInEPS679.h5  trainNetworkInEPS976.h5\n",
            "trainNetworkInEPS396.h5  trainNetworkInEPS680.h5  trainNetworkInEPS977.h5\n",
            "trainNetworkInEPS397.h5  trainNetworkInEPS681.h5  trainNetworkInEPS978.h5\n",
            "trainNetworkInEPS398.h5  trainNetworkInEPS682.h5  trainNetworkInEPS979.h5\n",
            "trainNetworkInEPS399.h5  trainNetworkInEPS683.h5  trainNetworkInEPS980.h5\n",
            "trainNetworkInEPS400.h5  trainNetworkInEPS684.h5  trainNetworkInEPS981.h5\n",
            "trainNetworkInEPS401.h5  trainNetworkInEPS685.h5  trainNetworkInEPS982.h5\n",
            "trainNetworkInEPS402.h5  trainNetworkInEPS686.h5  trainNetworkInEPS983.h5\n",
            "trainNetworkInEPS403.h5  trainNetworkInEPS687.h5  trainNetworkInEPS984.h5\n",
            "trainNetworkInEPS404.h5  trainNetworkInEPS688.h5  trainNetworkInEPS985.h5\n",
            "trainNetworkInEPS405.h5  trainNetworkInEPS689.h5  trainNetworkInEPS986.h5\n",
            "trainNetworkInEPS406.h5  trainNetworkInEPS690.h5  trainNetworkInEPS987.h5\n",
            "trainNetworkInEPS407.h5  trainNetworkInEPS691.h5  trainNetworkInEPS988.h5\n",
            "trainNetworkInEPS408.h5  trainNetworkInEPS692.h5  trainNetworkInEPS989.h5\n",
            "trainNetworkInEPS409.h5  trainNetworkInEPS693.h5  trainNetworkInEPS98.h5\n",
            "trainNetworkInEPS410.h5  trainNetworkInEPS694.h5  trainNetworkInEPS990.h5\n",
            "trainNetworkInEPS411.h5  trainNetworkInEPS695.h5  trainNetworkInEPS991.h5\n",
            "trainNetworkInEPS412.h5  trainNetworkInEPS696.h5  trainNetworkInEPS992.h5\n",
            "trainNetworkInEPS413.h5  trainNetworkInEPS697.h5  trainNetworkInEPS993.h5\n",
            "trainNetworkInEPS414.h5  trainNetworkInEPS698.h5  trainNetworkInEPS994.h5\n",
            "trainNetworkInEPS415.h5  trainNetworkInEPS699.h5  trainNetworkInEPS995.h5\n",
            "trainNetworkInEPS416.h5  trainNetworkInEPS700.h5  trainNetworkInEPS996.h5\n",
            "trainNetworkInEPS417.h5  trainNetworkInEPS701.h5  trainNetworkInEPS997.h5\n",
            "trainNetworkInEPS418.h5  trainNetworkInEPS702.h5  trainNetworkInEPS998.h5\n",
            "trainNetworkInEPS419.h5  trainNetworkInEPS703.h5  trainNetworkInEPS999.h5\n",
            "trainNetworkInEPS420.h5  trainNetworkInEPS704.h5  trainNetworkInEPS99.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvElRnqJK6hd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "9add331e-5ad4-4bd0-8a04-1a02308fcbd6"
      },
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('trainNetworkInEPS999.h5')\n",
        "model.summary()\n",
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 24)                72        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 48)                1200      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 147       \n",
            "=================================================================\n",
            "Total params: 1,419\n",
            "Trainable params: 1,419\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPEAAAFgCAIAAADl5AgMAAAABmJLR0QA/wD/AP+gvaeTAAAgAElE\nQVR4nO3dfVRT5x0H8OcmkJcbcqOyIGoCNWhlBbG6liJiD53HdszVVQgSFSk4erB263qsNq04jqNS\nR8GyzcF6UOfZ6hkGsUeRCd0qK2tPscdu+AYFRAaVRgy1GRGS8pI8++OuWYrhJUhyLw+/z1/c+9z7\n5Pck39w83CQ3FMYYAUAQAdcFADDFINOANJBpQBrINCCNn+tCfX39W2+9xVUpAEzOypUrd+7c6Vz8\n1nH65s2bFRUVPi8JgMm7cOFCfX296xq/ezc6efKkr+oB4H4lJyePWAPzaUAayDQgDWQakAYyDUgD\nmQakgUwD0kCmAWkg04A0kGlAGsg0IA1kGpAGMg1IA5kGpIFMA9Lcb6YzMzPlcjlFUZcuXZqSgqaK\nw+EoKiqKjY31aK9z584pFIqzZ896qapJuHDhwne/+12BQEBR1Ny5c/fv3++zmz516pRGo6EoiqKo\n4ODg1NRUn930/bjfTB85cuTw4cNTUsoUun79+uOPP75z506r1erRjjy8MkRMTMxnn3325JNPIoRa\nWlr27t3rs5tOSkpqb28PCwtTKBTd3d3Hjx/32U3fDwLnHpcvX3711Veff/75hx9+2NN9161b19vb\n+/TTT3ujMFc2m83T1xDf4G1hEzcFmaYo6v47mULLli07derUli1bxGIx17WM6ujRoyaTiesq3OBt\nYRM3mUxjjAsKCpYsWSIWixUKxe7du11b7XZ7Tk5OSEiIVCqNiooyGAwIoZKSEplMRtP0mTNnEhIS\nGIZRqVRlZWXOverq6qKjo2maZhhm6dKlFotltK6856OPPgoJCaEo6ne/+924Nf/2t7+VSCRBQUHb\nt2+fN2+eRCKJjY395JNP2NYXX3xRJBIFBweziy+88IJMJqMo6ssvv0QIvfTSSy+//PKNGzcoilq0\naBFCqKamhmGYvLy8idTpy8Im4sMPP3zooYcUCoVEIlm6dOl7772HEMrMzGQn4mFhYQ0NDQihjIwM\nmqYVCkVlZSUa5cF98803aZqWy+Umk+nll19esGBBS0vLBMv4P+yC7RePJzs7m6KogwcPms1mq9Va\nXFyMEGpoaGBbd+3aJRaLKyoqzGbznj17BALBxYsX2b0QQufPn+/t7TWZTKtXr5bJZIODgxjjvr4+\nhmHy8/NtNlt3d3diYmJPT88YXU3QY489tmzZsolvjzG+efMmQujQoUPOkY5WM8Y4KytLJpM1NTV9\n/fXXjY2Njz76qFwu//zzz9nWLVu2zJ0719lzQUEBQogdF8Y4KSkpLCzM2VpVVSWXy3Nzc0cr7Kmn\nnkIImc1mHxeGMWbn02PcaSdPnty3b99XX311586dmJiYwMBAZ1dCofCLL75wbrl58+bKykr277Fz\n8vOf//zQoUOJiYmfffbZGDeNMdZqtVqt1nWNx5m2Wq00Ta9du9a5hj1CsJm22Ww0Tet0OufGYrF4\nx44dzlptNhvbxD4T2traMMbXrl1DCFVVVbne0BhdTdBUZdptzRjjrKws1wf74sWLCKFf/vKX7KKn\n0Rmb20z7prBxM+3qjTfeQAiZTCaM8fvvv48Q2r9/P9vU29u7ePHi4eFh7ElOxnVvpj2ee7S1tVmt\n1jVr1rhtbWlpsVqtkZGR7KJUKg0ODm5ubr53S5FIhBAaGhpCCGk0mqCgoNTU1H379nV0dHjalc+4\n1nyvRx55hKZpTirkT2H+/v4IIbvdjhD6/ve//+CDD/7hD3/AGCOETpw4odPphEIh8vKD63Gmu7q6\nEEJKpdJta39/P0Jo79691Dc6OzvHPaEmlUpra2vj4uLy8vI0Go1Op7PZbJPriltisbinp4frKtzw\namF/+ctf4uPjlUqlWCx+5ZVXnOspitq+fXt7e/v58+cRQn/6059+8pOfsE1efXA9zrREIkEIDQwM\nuG1ls15UVOT6WjDikiJuRUREnD171mg06vV6g8FQWFg46a64MjQ09J///EelUnFdyEjeKOwf//hH\nUVERQujzzz/fsGFDcHDwJ5980tvbm5+f77pZenq6RCI5cuRIS0sLwzChoaHseq8+uB5nOjIyUiAQ\n1NXVuW1Vq9USicTT9xSNRmNTUxNCSKlUHjhwYMWKFU1NTZPrikMffPABxjgmJoZd9PPzG20y4GPe\nKOyf//ynTCZDCF29enVoaGjHjh0ajUYikYw4sTt79uyUlJTTp08XFhY+99xzzvVefXA9zrRSqUxK\nSqqoqDh69KjFYrly5UppaamzVSKRZGRklJWVlZSUWCwWu93e1dV169atsfs0Go3bt29vbm4eHBxs\naGjo7OyMiYmZXFc+5nA4zGbz8PDwlStXXnrppZCQkPT0dLZp0aJFX3311enTp4eGhnp6ejo7O113\nnDNnjtFo7OjouHv37tDQUHV19cTP5fmysHt7Hhoaun379gcffMBmOiQkBCH0/vvvf/3119evX3ee\nNHR6/vnnBwYGqqqqXN/J8u6D63rwn+C5vLt372ZmZgYGBgYEBMTFxeXk5CCEVCrV5cuXMcYDAwN6\nvT4kJMTPz499AjQ2NhYXF9M0jRBavHjxjRs3SktLGYZBCIWGhra2tnZ0dMTGxs6ePVsoFM6fPz87\nO5v979htV+OWV19fv2rVqnnz5rEDDA4Ojo2NraurG3fHQ4cOsSduaZpev3792DVjjLOysvz9/Rcs\nWODn58cwzDPPPHPjxg1nb3fu3HniiSckEsnChQt/9rOfsWfxFy1axJ5T+9e//hUaGiqVSuPi4rq7\nu8+dOyeXy52nCFxduHAhIiJCIBCwY8nLy/NZYb///e/DwsJGS867777LdqjX6+fMmTNr1qzk5GT2\n1H5YWJjz1CHGePny5a+99tqIcbl9cPPz86VSKUJIrVa/88474z5keErO5QGnrKysOXPmcF2FG3wr\n7Ic//GF7e7uXOp+Cc3nAFXvSioc4L8w5b7ly5Qr7muCzm55mmW5ubqZGp9PpvLQv8JRer79+/Xpr\na2tGRsbrr7/u09t2PWjD3GPiXnvtNfadjgceeODkyZNcl/N/PCksOztbIBCo1Wrnm+Fecu/cg8Iu\nnxguLy9PSUnB/PsMMQCjYa8/7XrR9Gk29wBgXJBpQBrINCANZBqQBjINSAOZBqSBTAPSQKYBaSDT\ngDSQaUAayDQgDWQakAYyDUjjd+8q9oNOAEwLFy5ccH59mPWt47RardZqtb4taaaorKw0Go1cV0Gg\nmJiYlStXuq6h4NPSvkFRlMFg2LhxI9eFkA/m04A0kGlAGsg0IA1kGpAGMg1IA5kGpIFMA9JApgFp\nINOANJBpQBrINCANZBqQBjINSAOZBqSBTAPSQKYBaSDTgDSQaUAayDQgDWQakAYyDUgDmQakgUwD\n0kCmAWkg04A0kGlAGsg0IA1kGpAGMg1IA5kGpIFMA9JApgFpINOANPA7Ad6ydevWS5cuORc7OjqU\nSqVMJmMX/f39z549u2DBAo6qI5mb3ygCU2LJkiXHjx93XdPX1+f8Ozw8HALtJTD38JZNmzZRFOW2\nyd/fPz093bflzCAw9/Ci733ve5cuXXI4HCPWUxTV3t7+wAMPcFEU+eA47UVpaWkCwch7mKKo6Oho\nCLT3QKa9KCUl5d6DtEAgSEtL46SeGQIy7UXBwcGrV68WCoUj1iclJXFSzwwBmfaurVu3ui4KBIIn\nnnhi7ty5XNUzE0CmvSs5OXnElHpEysGUg0x7F8MwP/jBD/z8/vc+gFAo/PGPf8xtScSDTHtdamqq\n3W5HCPn5+a1fv16hUHBdEeEg0163fv16qVSKELLb7Vu2bOG6HPJBpr1OIpEkJiYihGiaTkhI4Loc\n8vHu8x5dXV0ff/wx11VMMbVajRB69NFHKysrua5liqnV6pUrV3JdxbdhnjEYDFzfJcADWq2W68iM\nxLvjNAsT9ymUffv27d2713kChAzJyclcl+AGzKd9hLxA8xZk2kcg0D4DmQakgUwD0kCmAWkg04A0\nkGlAGsg0IA1kGpAGMg1IA5kGpIFMA9JApgFpINOANCRkOjMzUy6XUxTleh1RPnA4HEVFRbGxsRPf\n5dSpUxqNhnIhEomCgoLi4+MLCgrMZrP3qiUGCZk+cuTI4cOHua5ipOvXrz/++OM7d+60Wq0T3ysp\nKam9vT0sLEyhUGCMHQ6HyWQqLy9fuHChXq+PiIj49NNPvVczGUjINA9dvnz51Vdfff755x9++OH7\n6YeiqFmzZsXHxx87dqy8vPz27dvr1q3r7e2dqjqJREimR7sqLleWLVt26tSpLVu2iMXiqepTq9Wm\np6ebTKa33357qvok0nTNNMa4oKBgyZIlYrFYoVDs3r3btdVut+fk5ISEhEil0qioKPY7jiUlJTKZ\njKbpM2fOJCQkMAyjUqnKysqce9XV1UVHR9M0zTDM0qVLLRbLaF3dp5qaGoZh8vLyPN2RvWp1dXX1\ntBgmZzj+PuQ92Htz3M2ys7Mpijp48KDZbLZarcXFxQihhoYGtnXXrl1isbiiosJsNu/Zs0cgEFy8\neJHdCyF0/vz53t5ek8m0evVqmUw2ODiIMe7r62MYJj8/32azdXd3JyYm9vT0jNHVBD322GPLli0b\nsbKqqkoul+fm5o62l3M+PQKbP7VazZNharVaHn7Hdlpm2mq10jS9du1a5xr2OMRm2maz0TSt0+mc\nG4vF4h07duBvHmybzcY2sc+EtrY2jPG1a9cQQlVVVa43NEZXE+Q20+MaLdMYY3aGPXZtPhsmPzM9\nLecebW1tVqt1zZo1bltbWlqsVmtkZCS7KJVKg4ODm5ub791SJBIhhIaGhhBCGo0mKCgoNTV13759\nHR0dnnblG/39/RhjhmE8qm3aDfM+TctMd3V1IYSUSqXb1v7+foTQ3r17nad4Ozs7xz2hJpVKa2tr\n4+Li8vLyNBqNTqez2WyT68p7WltbEULh4eGI6GHep2mZaYlEghAaGBhw28pmvaioyPX1qL6+ftxu\nIyIizp49azQa9Xq9wWAoLCycdFdeUlNTgxBiL1BG8DDv07TMdGRkpEAgqKurc9uqVqslEomn7yka\njcampiaEkFKpPHDgwIoVK5qamibXlZd0d3cXFRWpVKpt27Yhcod5/6ZlppVKZVJSUkVFxdGjRy0W\ny5UrV0pLS52tEokkIyOjrKyspKTEYrHY7faurq5bt26N3afRaNy+fXtzc/Pg4GBDQ0NnZ2dMTMzk\nuhpXdXX1uOfyMMZ9fX0OhwNj3NPTYzAYVq1aJRQKT58+zc6n+T9Mznjpf89Jm+C5vLt372ZmZgYG\nBgYEBMTFxeXk5CCEVCrV5cuXMcYDAwN6vT4kJMTPz499AjQ2NhYXF9M0jRBavHjxjRs3SktL2XCE\nhoa2trZ2dHTExsbOnj1bKBTOnz8/Ozt7eHh4tK7GLa++vn7VqlXz5s1j7+Tg4ODY2Ni6ujq29dy5\nc3K5fP/+/ffuWFlZGRUVRdO0SCRif2CAPdERHR2dm5t7584d1405HyY/z3vw7vcRy8vLU1JS+FYV\ncIu9Xt7Jkye5LuRbpuXcA4AxQKY91tzcTI1Op9NxXeBMBxcm9Fh4eDhMjfgMjtOANJBpQBrINCAN\nZBqQBjINSAOZBqSBTAPSQKYBaSDTgDSQaUAayDQgDWQakAYyDUgDmQak4elnTcvLy7kuAYyvq6tL\npVJxXcVIPM10SkoK1yWACdFqtVyXMBLvvo9IKoqiDAbDxo0buS6EfDCfBqSBTAPSQKYBaSDTgDSQ\naUAayDQgDWQakAYyDUgDmQakgUwD0kCmAWkg04A0kGlAGsg0IA1kGpAGMg1IA5kGpIFMA9JApgFp\nINOANJBpQBrINCANZBqQBjINSAOZBqSBTAPSQKYBaSDTgDSQaUAayDQgDWQakAYyDUgDmQak4elv\nXxCgtLTUbDa7rjlz5sy///1v52J6evrcuXN9Xhf54LcvvCUrK6u0tFQsFrOLGGOKoti/h4eHFQpF\nd3e3v78/dwUSC+Ye3rJp0yaE0MA3BgcHnX8LBIJNmzZBoL0EjtPe4nA45s2bZzKZ3LZ+9NFHq1at\n8nFJMwQcp71FIBCkpqaKRKJ7m+bNmxcbG+v7kmYIyLQXbdq0aXBwcMRKf3//tLQ059waTDmYe3iX\nRqNxPdfBunTp0rJlyzipZyaA47R3paWljfhfUKPRQKC9CjLtXampqUNDQ85Ff3//jIwMDuuZCWDu\n4XVRUVHXrl1z3s+tra2LFy/mtiSywXHa69LS0oRCIUKIoqjly5dDoL0NMu11mzdvttvtCCGhUPjs\ns89yXQ75INNeN3/+/NjYWIqiHA5HcnIy1+WQDzLtC1u3bsUYP/744/Pnz+e6lhkA84zBYOD6LgEe\n0Gq1XEdmJJ5+1pS8ZB88eDArKysgIIDrQqZSUVER1yW4wdNMb9y4kesSplhsbKxKpeK6iil28uRJ\nrktwA+bTPkJeoHkLMg1IA5kGpIFMA9JApgFpINOANJBpQBrINCANZBqQBjINSAOZBqSBTAPSQKYB\naSDTgDQkZDozM1Mul1MUdenSJa5r+Z/c3NyHHnqIYRixWLxo0aJXXnmlr69vIjueOnVKo9FQLkQi\nUVBQUHx8fEFBwYiL/wK3SMj0kSNHDh8+zHUV31JbW/vTn/60o6Pjyy+/fOONN379619P8JuISUlJ\n7e3tYWFhCoUCY+xwOEwmU3l5+cKFC/V6fURExKeffurt4qc7EjLNQwEBAVlZWXPmzJHL5Rs3btyw\nYUNNTc3Nmzc97YeiqFmzZsXHxx87dqy8vPz27dvr1q3r7e31Rs3EICTTfLukYlVVFXtND9Z3vvMd\nhJDVar2fPrVabXp6uslkevvtt++3PqJN10xjjAsKCpYsWSIWixUKxe7du11b7XZ7Tk5OSEiIVCqN\niopiv91YUlIik8lomj5z5kxCQgLDMCqVqqyszLlXXV1ddHQ0TdMMwyxdutRisYzWlae++OILqVS6\ncOFCdrGmpoZhmLy8PE/7SU9PRwhVV1fzc5h8wfWXfEdi781xN8vOzqYo6uDBg2az2Wq1FhcXI4Qa\nGhrY1l27donF4oqKCrPZvGfPHoFAcPHiRXYvhND58+d7e3tNJtPq1atlMtng4CDGuK+vj2GY/Px8\nm83W3d2dmJjY09MzRlcT19/fL5fLX3zxReeaqqoquVyem5s72i7O+fQIbP7UajVPhqnVann4vfFp\nmWmr1UrT9Nq1a51r2OMQm2mbzUbTtE6nc24sFot37NiBv3mwbTYb28Q+E9ra2jDG165dQwhVVVW5\n3tAYXU1cdnb2gw8+aLFYJr7LaJnGGLMzbJ4Mk5+ZnpZzj7a2NqvVumbNGretLS0tVqs1MjKSXZRK\npcHBwc3NzfduyV7En73uqEajCQoKSk1N3bdvX0dHh6ddjebdd98tLy9/77335HL5xPcaTX9/P8aY\nYRiPavPBMHllWma6q6sLIaRUKt229vf3I4T27t3rPMXb2dk57v9nUqm0trY2Li4uLy9Po9HodDqb\nzTa5rpxOnDjxq1/96oMPPnjggQcmProxtLa2IoTCw8MRn4bJN9My0xKJBCE0MDDgtpXNelFRkevr\nUX19/bjdRkREnD171mg06vV6g8FQWFg46a4QQocOHTp+/Hhtbe0UXk+spqYGIZSQkIB4M0wempaZ\njoyMFAgEdXV1blvVarVEIvH0PUWj0djU1IQQUiqVBw4cWLFiRVNT0+S6whjr9fqrV6+ePn16Ci+8\n1N3dXVRUpFKptm3bhngwTN6alplWKpVJSUkVFRVHjx61WCxXrlwpLS11tkokkoyMjLKyspKSEovF\nYrfbu7q6bt26NXafRqNx+/btzc3Ng4ODDQ0NnZ2dMTExk+uqqanpzTffPHz4sL+/v+u73IWFhewG\n1dXV457Lwxj39fU5HA6McU9Pj8FgWLVqlVAoPH36NDuf5nyY/OWdfz0nb4Ln8u7evZuZmRkYGBgQ\nEBAXF5eTk4MQUqlUly9fxhgPDAzo9fqQkBA/Pz/2CdDY2FhcXEzTNEJo8eLFN27cKC0tZcMRGhra\n2tra0dERGxs7e/ZsoVA4f/787Ozs4eHh0boau7arV6+6vasLCgrYDc6dOyeXy/fv33/vvpWVlVFR\nUTRNi0QigUCAvnkrMTo6Ojc3986dO64bcztMzNfzHrz77Yvy8vKUlBS+VQXcYj/Ewrer5k3LuQcA\nY4BMe6y5uZkanU6n47rAmY6n1+rls/DwcJga8RkcpwFpINOANJBpQBrINCANZBqQBjINSAOZBqSB\nTAPSQKYBaSDTgDSQaUAayDQgDWQakAYyDUjD08+a8u36d2A0Wq2W6xJG4t13t7q6uj7++GOuq5h6\nKSkpL7300sqVK7kuZIqp1Wq+DYp3mSYVRVEGg2Hjxo1cF0I+mE8D0kCmAWkg04A0kGlAGsg0IA1k\nGpAGMg1IA5kGpIFMA9JApgFpINOANJBpQBrINCANZBqQBjINSAOZBqSBTAPSQKYBaSDTgDSQaUAa\nyDQgDWQakAYyDUgDmQakgUwD0kCmAWkg04A0kGlAGsg0IA1kGpAGMg1IA5kGpOHpb18QoLOz0263\nu665fft2e3u7c3HevHlSqdTndZEPfifAWxISEmpqakZr9fPz6+7uDgwM9GVJMwTMPbxFp9ON9ktL\nAoFg7dq1EGgvgUx7S2Jior+//2itW7du9WUxMwpk2lvkcvmPfvQjt7H29/d/+umnfV/SDAGZ9qIt\nW7YMDw+PWOnn57dhw4aAgABOSpoJINNetG7dOplMNmKl3W7fsmULJ/XMEJBpLxKLxVqtViQSua4M\nCAh48sknuSppJoBMe9fmzZsHBwedi/7+/jqdbkTKwdSC89Pe5XA45s6d++WXXzrX/P3vf4+Pj+eu\nIvLBcdq7BALB5s2bnQdmpVK5evVqbksiHmTa6zZt2sROP0QiUVpamlAo5LoiwsHcw+swxqGhoTdv\n3kQIXbx48ZFHHuG6IsLBcdrrKIpKS0tDCIWGhkKgfYB3n8urr69/6623uK5iilksFoSQTCZLTk7m\nupYptnLlyp07d3Jdxbfw7jh98+bNiooKrquYYgzDKBQKlUrFdSFT7MKFC/X19VxXMRLvjtOskydP\ncl3CFHvvvfeeeuoprquYYvx82eHdcZpU5AWatyDTgDSQaUAayDQgDWQakAYyDUgDmQakgUwD0kCm\nAWkg04A0kGlAGsg0IA1kGpAGMg1IQ0KmMzMz5XI5RVGXLl3iupb/yc/PDw8Pl0qlMpksPDz8F7/4\nBfu1gHGdOnVKo9FQLkQiUVBQUHx8fEFBgdls9nblBCAh00eOHDl8+DDXVXzLhx9++Nxzz33++ee3\nb99+/fXX8/PztVrtRHZMSkpqb28PCwtTKBQYY4fDYTKZysvLFy5cqNfrIyIiPv30U28XP92RkGke\nEolEL7zwglKpDAgISE5OfuaZZ/72t7/dunXL034oipo1a1Z8fPyxY8fKy8tv3769bt263t5eb9RM\nDEIyPdqVnrny7rvvSiQS5+KCBQsQQn19fffTp1arTU9PN5lMb7/99v3WR7TpmmmMcUFBwZIlS8Ri\nsUKh2L17t2ur3W7PyckJCQmRSqVRUVEGgwEhVFJSIpPJaJo+c+ZMQkICwzAqlaqsrMy5V11dXXR0\nNE3TDMMsXbqUnQG77cpT169fnzVrVmhoKLtYU1PDMExeXp6n/aSnpyOEqqur+TlMvsA8w96b426W\nnZ1NUdTBgwfNZrPVai0uLkYINTQ0sK27du0Si8UVFRVms3nPnj0CgeDixYvsXgih8+fP9/b2mkym\n1atXy2SywcFBjHFfXx/DMPn5+Tabrbu7OzExsaenZ4yuJmJwcLCrq+vQoUNisfidd95xrq+qqpLL\n5bm5uaPt6JxPj8DmT61W82SYWq1Wq9VO8N7wmWmZaavVStP02rVrnWvY4xCbaZvNRtO0TqdzbiwW\ni3fs2IG/ebBtNhvbxD4T2traMMbXrl1DCFVVVbne0BhdTcTcuXMRQoGBgb/5zW/YSE3QaJnGGLMz\nbJ4Mk5+ZnpZzj7a2NqvVumbNGretLS0tVqs1MjKSXZRKpcHBwc3NzfduyV7GbmhoCCGk0WiCgoJS\nU1P37dvX0dHhaVdu3bx502Qy/fnPf/7jH/+4fPlyk8nkwSDd6e/vxxgzDONRbd4eJt9My0x3dXUh\nhJRKpdvW/v5+hNDevXudp3g7OzutVuvYfUql0tra2ri4uLy8PI1Go9PpbDbb5Lpy8vf3VyqVTz75\n5IkTJxobG9944w0PBulOa2srQig8PBzxaZh8My0zzZ5SGBgYcNvKZr2oqMj19Wgil1aJiIg4e/as\n0WjU6/UGg6GwsHDSXY2waNEioVDY2Njo6Y4jsD9Ol5CQgHg5TJ6YlpmOjIwUCAR1dXVuW9VqtUQi\n8fQ9RaPR2NTUhBBSKpUHDhxYsWJFU1PT5Lq6c+fO5s2bXddcv37dbrer1WqP+hmhu7u7qKhIpVJt\n27YN8WCYvDUtM61UKpOSkioqKo4ePWqxWK5cuVJaWupslUgkGRkZZWVlJSUlFovFbrd3dXWN+36H\n0Wjcvn17c3Pz4OBgQ0NDZ2dnTEzM5LqSyWR//etfa2trLRbL0NBQQ0PDs88+K5PJnNeVq66uHvdc\nHsa4r6/P4XBgjHt6egwGw6pVq4RC4enTp9n5NOfD5C8v/e85aRM8l3f37t3MzMzAwMCAgIC4uLic\nnByEkEqlunz5MsZ4YGBAr9eHhIT4+fmxT4DGxsbi4mKaphFCixcvvnHjRmlpKRuO0NDQ1tbWjo6O\n2NjY2bNnC4XC+fPnZ2dnDw8Pj9bVuOWtX79+4cKFAQEBYrE4LCxMp9NdvXrV2Xru3Dm5XL5///57\nd6ysrIyKiqJpWiQSCQQC9M1bidHR0bm5uXfu3HHdmPNh8vO8B++uP11eXp6SksK3qoBb7PXy+HZx\nw2k59wBgDJBpjzU3N1Oj0+l0XBc40/H0Wr18Fh4eDlMjPoPjNCANZBqQBv0pVzsAAAB1SURBVDIN\nSAOZBqSBTAPSQKYBaSDTgDSQaUAayDQgDWQakAYyDUgDmQakgUwD0kCmAWl4+llT9gsUgOcuXLgQ\nExPDdRUj8e44rVarJ3hZW8C5mJiYlStXcl3FSLz7PiIA94l3x2kA7hNkGpAGMg1IA5kGpPkvg/M1\nJ13adqkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9DX4iPCNtoN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}